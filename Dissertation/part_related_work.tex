\chapter{Обзор}
\label{chapter_related_work}

\section{Введение}
\label{rw:introduction}

Разделить Java и Си

С ростом популярности многопоточных приложений растет актуальность поиска ошибок в них. Анализ и тестирование параллельных программ значительно сложнее, чем последовательных. Для применения к многопоточным программам развиваются такие техники, как проверка моделей, статический и динамический анализ кода, генерация тестов и дедуктивная верификация. Есть несколько причин, почему до сих пор сохраняется такое разнообразие техник.
1) Пока не существует метода, который показал бы себя эффективным в общем случае. 
2) Нет ясного способа сравнения подходов. Каждый инструмент имеет свой входной и выходной формат, и для того чтобы сравнивать на одном наборе тестов необходимо переписать все инструменты к одному виду. Кроме того, часто бывает, что тесты, на которых получали результаты авторы, недоступны для остальных исследователей.
В настоящее время следить за успехами каждого подхода. В качестве одного из шагов в сторону обобщения в статье~\cite{Rungta:2009} представляется обзор некоторых существующих методов анализа многопоточных программ.
В статье предлагается набор тестов для оценки качества инструментов анализа многопоточных программ. Набор состоит из тестов Dwyer FSE 2006 и тестов IBM[cite], представляющий собой 45 уникальных программ на Java. Также в статье представлены результаты сравнительного анализа инструментов CalFuzzer, ConTest, CHESS и Java PathFinder. CHESS используется для проверки C\# программ, остальные - для Java программ. Java PathFinder (JPF) реализует идею уточнения по контрпримерам и динамической редукцией частичного порядка. ConTest и CalFuzzer являются динамическими инструментами. 
CHESS анализирует возможные варианты переключения контекста, ограничивая их число некоторым фиксированным K. Так как он является динамическим инструментом, он требует написание некоторого теста. Важной особенностью является то, что он не создает состояния.
ConTest вносит некоторую случайность в порядок выполнения некоторыхе операцийи синхронизации, выполняющихся в параллельных потоках в процессе выполнения программы.
CallFuzzer состоит из двух частей. RaceFuzzer сначала определяет два потенциальных состояния, в которых возможно состояние гонки. При динамическом запуске этот инструмент пытается привести состояние потоков в выбранныепредполагаемые и проверяет, имело ли место реальное состояние гонки. DeadlockFuzzer сходным образом ищет состояния взаимных блокировок.
Авторами была создана wiki с результатами сравнения инструментов: 
% http://vv.cs.byu.edu → Research Projects → Concurrency Tool Comparison[cite]
В статье представлены результаты запуска на некоторых тестах.

\cite{Wesonga:2011} - инструмент для помощи JPF( визаилизация...)
\cite{Dourado:2016} - небольшой набор программ

\section{Методы верификации многопоточных программ с использованием подход ограниченной проверки моделей}
\label{rw:bmc}

Традиционно идеи такого подхода применяются к небольшим программам. Наблюдение, что состояние гонки проявляются уже при небольшом числе переключений контекста, позволило ограничить число переключений некоторым фиксированным K. Методы, принадлежащие данному направлений отличаются математической строгостью доказательства отсутствия состояний гонок.
Идеи подхода для проверки моделей многопоточных программ получили развитие в статье~\cite{Cordeiro:2011}. В данном подходе параллельность моделируется случайным переключением между активными потоками. Считается, что потоки взаимодействуют между собой только через глобальные переменные. Таким образом, переключение потока имеет смысл в случае, если в текущем состоянии происходит доступ к глобальной переменной. 
Сначала строится абстрактное дерево достижимости (ART). В узле этого дерева хранится информация об активном в данный момент потоке, состояниях каждого из потоков, накопленные ограничения. Ограничения представляют собой предикаты, полученные из условных переходов. 
В статье описаны несколько подходов к верификации программы.
Ленивый подход предполагает, что дерево достижимости обходится в глубину, собираются все полученные ограничения для пути и для каждого узла дерева вызывается обычная процедура для ограниченной проверки модели. Обход дерева останавливается, если была доказано отрицание проверяемого свойства, то есть, найдена ошибка, или если проверены все узлы дерева.
Подход с записью расписания (schedule recording) добавляет к формуле ограничения на планировщик, что позволяет объединить все возможные варианты исполнения программы объединяются в одну формулу и отдать решателю.
Расширяющийся подход (under-approximation and widening approach) основан на том, что сначала строится формула для частного случая взаимодействия процессов, и она проверяется решателем. Если найдена ошибка, значит, более общая модель уже не нужна. Иначе, постепенно отбрасываются ограничения на планировщик, тем самым покрывается все больше вариантов параллельной работы. 
Моделирование примитивов синхронизации происходит с помощью конструкции assume(P), которая рассматривает пути выполнения программы, для которых в данный момент выполнен предикат P. Операция захвата блокировки m представляет собой атомарную последовательность assume(m==0); m=1. Однако для того, чтобы оставалась возможность находить ошибки связанные с взаимной блокировкой (dead locks), для каждого потока вычисляется его состояние: ожидание другого потока, ожидание освобождения блокировки, ожидание сигнала или свободное выполнение. Если нет ни одного потока в свободном состоянии, это означает взаимную блокировку.
В экспериментах использовался ESBMC[cite] с решателем Z3[cite]. Для сравнения использовался CHESS, динамический инструмент для тестирования C\# программ, и SATABS[cite], инструмент для верификации многопоточных программ с помощью метода CEGAR[cite]. Инструмент CHESS реализует подход, похожий на ленивый, и эффективен только для программ с небольшим количеством потоков, после 5 потоков начинаются проблемы со временем. Число переключений контекста также невелико. Для 6 переключений уже наблюдается таймаут. Подход, предлагаемый в данной статье, позволяет анализировать модели с 10ю переключениями контекста. SATABS имеет проблемы с моделированием массивов и также не справляется с большими программами: из 21 теста[cite] он справился лишь в трех случаях. Предлагаемый ленивый подход успешно прошел все, оставшиеся два завершили 16 тестов.
В будущем планируется попробовать интерполяцию Крейга.

Похожие идеи были представлены в статье ~\cite{Threader:2011}. В ней в целом описывается архитектура инструмента Threader и на абстрактном уровне описывается, что же делает инструмент.
Threader ищет формальное доказательство корректности. Оно может представлять собой либо некоторое глобальное условие, которое выводится из начальных данных, является инвариантом при всех преобразованиях и из него следует доказываемое свойство. Другой вариант - это множество локальных условий для каждого потока, каждое из которых удовлетворяет этим же трем условиям. Третий вариант - это те же локальные условия и некоторые ограничение на взаимодействие потоков. Это повторяет те три уровня абстракции, которые описывались в предыдущей статье.
Для экспериментов использовались 15 тестов, не содержащих ошибку. Поиск первого типа доказательства завершился только в двух случаях. Поиск доказательства второга типа завершился в 12 случаях и, в среднем, был быстрее, чем поиск доказательства третьего типа, который завершился в 13 случаях. 
Более полное содержание метода было описано авторами в статье ~\cite{Gupta:2011:POPL,Gupta:2011}.
В этой статье рассказывается о методе формального доказательства корректности многопоточных программ. Для программы выписываются начальные условия finit, представляющие собой предикаты на переменные программы, и записываются утверждения ferr, которые описывают ошибочное состояние программы. Далее, производится проверка, можно ли вывести finit->ferr. Важно отметить, что в переменные состояния программы включен счетчик инструкций (program counter).
Сначала строятся абстрактные деревья достижимости и окружения (Abstract Reachability and Environment Trees, ARETs). Если в процессе построения было получено состояние, которое не противоречит ошибочному, начинается уточнение абстракции. Строятся дизъюнкты Хорна (Horn clauses), решением которых являются те предикаты, которые уточняют абстракцию. После добавления полученных предикатов в модель, ARETs перестраиваются. В случае, если уточнение состояние ничего не дало, уточняется эффект, который оказывает один поток на другой путем изменения глобальных переменных. Стоит отметить, что в данном подходе, также как и в статье~\cite{Cordeiro:2011}, разделяемая память представлена только глобальными переменными, в то время как указатели не рассматриваются вообще. Полученный эффект учитывается при переходах из состояния в состояние. Возможны два варианта доказательства: обычное и модульное (modular), которое означает, что в доказательстве не были использованы локальные переменные другого потока. 
Отдельно в статье описывается метод разрешения дизъюнктов Хорна при некоторых незначительных упрощениях. 
Для построения промежуточного представления используется CIL, основной алгоритм написан на языке Пролог. На вход подается файл с исходным кодом функций, которые могут выполняться параллельно, описание ошибочной ситуации и начального состояния. 
Для оценки результатов использовались примеры, являющиеся упрощенными моделями некоторых реальных программ, таких, как драйвера ОС Windows и Linux. Проводилось сравнение между двумя вариантами работы инструмента: обычное доказательство и модульное доказательство. Последний способ пытается не использовать предикаты с локальными переменными другого процесса так долго, как это возможно. Очевидно, что если модульного доказательства не существует, второй способ потратит слишком много времени на поиск того, чего нет. Эксперименты показали, что в некоторых случаях такое ограничение может помочь, так как у первого способа будет слишком большой выбор предикатов, и модель получится слишком точной прежде, чем доказательство будет получено. Время работы инструмента с модульным типом доказательства составляет, в среднем, 2-3 с на 10 операций, однако встречаются примеры со временем работы 3 с на одну операцию. Время работы инструмента с поиском любого доказательства незначительно меньше. Во всех представленных тестах, в которых существует модульное доказательство, инструмент нашел его. 
В статье~\cite{Threader:svcomp} авторы предоставляют результаты запуска инструмента на некотором общедоступном наборе тестов.
Threader состоит из двух частей: разбор исходного кода программы с помощью библиотеки CIL и проверка полученной модели с помощью решателя. Последняя часть реализована на Прологе и использует линейную арифметику.
Дополнительно в интерфейсе (frontend) CILa был реализован контекстно-чувствительный анализ указателей. Отдельной проблемой является создание потоков в цикле, так как методы проверки моделей позволяют рассмотреть только конечное число итераций. Для этого в том же интерфейсе был реализован алгоритм вычисления количества итераций цикла. Еще одна проблема с анализом элементов массива еще не решена. Threader применим в случаях, когда используются дополнительные средства синхронизации, а не только блокировки. Threader не ограничивает число возможных переключений контекста.
Threader запускался на 32 тестах из категории «Параллельность» и набрал 43 балла из 49 возможных. Правильный вердикт был выдан на 28 тестах.

В статье~\cite{Gupta:2010} авторы предлагают интересное расширение метода CEGAR[cite]. В отличие от классического метода CEGAR, предлагаемый подход сохраняет все ложные контрпримеры, и новая итерация уточнения использует их все. Предикаты, полученные в ходе уточнения не добавляются к старым, а полностью их заменяют, поэтому метод носит название немонотонный. Утверждается, что конкретный набор предикатов не может быть выделен дважды. Таким образом, процесс уточнения абстракции конечен. 
В инструменте используется абстракция и по данным, и по точкам программы, но предпочтение отдается уточнению абстрактного состояния данных программы, которое производится по классической, монотонной схеме. Немонотонный подход используется для выделения классов эквивалентности точек программы. Эксперименты на пяти тестах показали, что немонотонный подход работает быстрее и выделяет меньше классов эквивалентности.

В статье ~\cite{Lahiri:2009} авторы представляют инструмент для проверки моделей для применения к низкоуровневому системному коду. Сначала производится трансляция исходной Си программы в язык Boogie, чтобы избавиться от таких конструкций, как динамическое выделение памяти, арифметика указателей, преобразование типов. Далее, параллельная программа преобразуется в последовательную, и для нее уже строятся формулы, которые проверяются с помощью SMT решателя. Для того чтобы повысить масштабируемость метода, применяется слайсинг по полям структур. Такая идея базируется на предположении, что для проверки конкретного свойства необходимо наблюдение за очень небольшим количством полей. Построение множества отслеживаемых полей производится с помощью метода CEGAR. 
Трансляция Си-программы в программу на языке Boogie происходит с помощью инструмента HAVOC. Заявлено, что этот инструмент поддерживает все конструкции языка Си. В этом языке используется одна статическая карта памяти. 
Для преобразования параллельной программы фиксируется число возможных потоков n и число возможных переключений контекста K. Требуется построить такую последовательную программу, которая покрывала бы все возможные варианты выполнения n потоков, каждый из которых прерывался бы не более K раз. Для моделирования переключения контекста для карты памяти глобальных переменных создаются K копий. И переключение контекста моделируется переключением работы с одной картой памяти на другую. Все потоки выполняются один за другим. 
Для верификации программа освобождается от циклов и вызовов функций. Это может привести к потере точности, так как циклы разворачиваются на конечную глубину. Кроме того, принимается предположение о том, что в системных программах редко встречается рекурсия, чтобы можно было заменить вызов функции на ее тело. Для того чтобы повысить масштабируемость, применяется слайсинг по полям структур. Выделяется некоторое множество полей структур, доступы к которым обрабатываются. Изначально это множество пустое. В процессе уточнения по методу CEGAR в него добавляются все новые поля, пока процесс доказательства не будет завершен. 
Инструмент запускался на четырех реальных драйверах ОС Windows и в одном даже нашел ошибку. Причем проверяться может некоторое свойство, задаваемое пользователем, например, использование указателя после его освобождения. Было проведено сравнение результатов для случая, когда множество отслеживаемых структур задается вручную, и случаем с уточнением. Уточнение во многих случаях строило большее множество, но на 1-2 поля, то есть отличие составляло несколько процентов, а в некоторых по размеру совпадало с построенным вручную. К сожалению, время работы инструмента приведено только для варианта с уточнением. Оно составляет порядка часа на программу из 600 операторов (locations). 

Продолжение с результатами: ~\cite{Ghafari:2010}

В статье ~\cite{Basler:2009} авторы представляют идею абстракции по программному счетчику. Статья посвящена важной задаче исследования пространства состояний, основанных на BDD-представлении для логических программ. Проблема комбинаторного взрыва локальных состояний решается с помощью метода CEGAR. 
Сначала исходная программа транслируется в логическую, в которой все переменные могут принимать только значения {0,1}. Количество переменных получившейся программы потенциально может быть бесконечно. 
Для снижения затрат ресурсов используется абстракция программного счетчика (counter abstraction). Два глобальных состояния считаются эквивалентными относительно перестановки локальных состояний, количество компонент в локальном состоянии одинаково. Чтобы реализовать эту идею, вводится счетчики для каждого локального состояния, и при переходе из одного состояния в другое увеличивается счетчик полученного и уменьшается для исходного. 
Две основные идеи для снижения затрат ресурсов. 
1) Вместо того, чтобы статически транслировать каждую операцию в обновление программного счетчика, он обновляется динамически, “на лету”. Это приводит к сокращению возможных значений программного счетчика на пути выполнения.
2) Вместо хранения всех программных счетчиков для локальных состояний хранятся только ненулевые счетчики. Этот пункт основан на наблюдении, что для длинных путей, в которых число операций значительно больше числа потоков, большинство программных счетчиков равны нулю.
Для того чтобы еще более повысить скорость работы применяется объединение символических состояний. Оно может произойти, если два состояния отличаются только значением глобальных переменных или локальным состоянием в одном из потоков. 
Для экспериментов было выбрано два набора тестов. Один из них сгенерирован инструментом SatAbs[cite] на основе ядра ОС Linux (http://www.cprover.org/boolean-programs). Второй набор тестов сгенерирован с помощью инструмента SLAM[cite]. N потоков исполняют одну и ту же функцию main. Взаимодействие между потоками происходит только с помощью глобальных переменных. Предложенный алгоритм сравнивался с тем, который реализован в инструменте Murphi[cite]. Предлагаемый подход оказался быстрее в 94\% случаев. Применение объединения состояний при анализе позволяет получить ускорение на 83\%. 

Отдельно следует отметить статьи, посвященные проблеме трансляции параллельной программы в последовательную с последующей ее верификацией существующими инструментами. В статье ~\cite{Ghafari:2010} авторы предлагают три варианта трансляции.
Контекстно-ограниченная проверка моделей - это подход к проверке многопоточных программ, когда число активных потоков ограничивается некоторым числом в процессе верификации. Взаимодействие между потоками возможно только с помощью глобальных переменных, причем доступ к ним является атомарным. В каждый момент времени только один поток может быть активен. Переключение контеста происходит в случайный момент времени. 
В статье рассматриваются несколько вариантов к трансляции параллельной праграммы в последовательную. 
Первый вариант - это EMC, использование явного счетчика команд. В этом случае состояние программы включает в себя все локальные переменные и счетчик команд для каждого потока. Это самый простой способ, он требует много времени и памяти.
Второй вариант — Lal-reps (LR). В этом случае каждый поток символически выполняется независимо от других, с учетом того, что значения глобальных переменных могут измениться случайным образом. Задача упрощается тем, что заранее задается, когда происходит переключения контекста, а значит, задаюется и точки, когда глобальные переменные приобретают новые значения. 
Третий вариант - LMP. Его основное отличие от предыдущего подхода в том, что он предписывает глобальным переменным не случайные значения, а только те, которые возможны во время выполнения программы. После переключения контекста текущее локальное состояние потока сбрасывается, и чтобы его восстановить приходится заново исполнять поток из начального состояния с учетом того, что становятся известны значения глобальных переменных до переключения.
Попытки применения подхода с ограничиваемым контекстомконтекстно-ограниченными проверками показали, что он плохо масштабируется и на реальных программах пока не может быть использован. Авторы сравнивают две парагдимы к проверкеи моделей. Одна из них - это логическая проверка моделей, при которой формулы строятся для конечного пути, а проверяется их выполнимость. Второй вариант - это условная верификация (verification-condition, VC), когда для построения формул требуется пред- и постусловия и формальные правила преобразования. Эксперименты показали, что эти две парагдимы сильно отличаются, и для них нужны различные способы трансляции. LR - лучший способ для VC-проверки. Что интересно, самыйая простой способ EMC оказался лучше, чем LMP почти во всех тестах.
Еще два варианта трансляции рассматриваются в статье ~\cite{Torre:2009}. В ней представлен подход ленивой трансляции параллельной программы в последовательную с ограниченным числом переключений контекста. Важной особенностью описываемого метода является то, что множество достижимых состояний полученной программы является тем же, что и для исходной программы. Кроме того, была реализована вторая стратегия, противоположная, - нетерпеливая трансляция. Известные методы сохраняют локальное состояние потока перед переключением контекста. Для того чтобы избежать этого предлагается использовать копии глобальных переменных для каждого из переключений контекста. Таким образом, после каждого переключения ведется работа со своей картой памяти, а условия на равенство их между собой будут выписаны позднее. 
Подход нетерпеливой трансляции предполагает, что поток выполняется сразу от начала и до конца. В начале карты памяти инициализируются произвольными значениями. В точках переключения контекста происходит смена карты памяти.
При ленивой трансляции выполнение происходит постепенно, с реальным переключением. Инициализируется только первая карта памяти. Далее, при переключении контекста она копируется во вторую и происходит анализ второго потока. При переключении контекста обратно в первый поток происходит его выполнение заново, но уже до следующей точки переключения контекста. 
Для оценки результатов использовался один тестовый пример и второй тест, сделанный на основе драйвера ОС Windows. Результаты показали, что нетерпеливый подход тратит значительно больше памяти и времени на проверку.

*Seq: ~\cite{Inverso:2014, Tomasco:2015}

Также проблеме трансляции посвящена статья KSSK09. В ней представлен фраймворк для статической проверки моделей, предназначенный для анализа кода ядра ОС. В отличие от традиционных подходов, в которых модель системы пишется вручную, данный инструмент автоматически транслирует программу на языке C СИ в модель на языке Promela[cite]. Полученная модель верифицируется с помощью инструмента SPIN[cite]. Другие особенности инструмента:
1) Возможность воспроизводить контрпример. Это особенно важно для поиска причин состояния гонки.
2) Возможность уточнения сгенерированной модели. 
3) Проверка не только программы, но и патча. Это особенно важно при анализе таких больших систем, как ядро ОС. 
Большая часть статьи занимает анализ трех найденных багов.

В статье ABQ09 авторы рассматривают проблему трансляции программ с динамическим созданием потоков, т.н. асинхроннными вызовами. Число переключений контекста вновь созданного потока ограничивается числом оставшихся переключений контекста родительского потока минус единица. Однако число всех переключений контекста остается неограниченным, так как число создаваемых потоков может быть бесконечно. Эта задача сводится к вопросу о покрытии сетей Петри. Ее решение основано на том, что число потоков, создаваемых из конкретного состояния, включающего локальные и глобальные переменные, конечно. Таким образом на первых L итерациях планирования разрешено создание новых потоков, а в оставшихся K - L итерациях (K - общее возможное число переключений контекста) возможно только переключение, как в классическом подходе. Далее, применяя нетревиальные преобразования, авторы доказывают несколько теорем из которых следует алгоритмическая разрешимость задачи за конечное время.  
Статья крайне теоретизирована, и никаких реальных экспериментов нет.

В статье KSG09 рассматривается идея статического анализа с последующей проверкой модели.
Поток описывается множеством процедур, в котором выделяется точка входа, множеством глобальных переменных и множеством локальных переменных. Для каждой процедуры задаются входные параметры, возвращаемое значение, локальные переменные и граф потока управления. Многопоточная программа включает в себя фиксированное число потоков и множество разделяемых переменных, которые являются глобальными для каждого потока. Рассматриваются стандартные примитивы синхронизации: блокировки, рандеву и посылка сигналов. 
Граф транзакций представляет собой граф потока управления для всех потоков.Так, узлом этого графа является множество точек программы для каждого из потоков. Каждая дуга представляет собой переход только в одном потоке. Для того, чтобы построить граф транзакций сначала определяются разделяемые переменные. Ключевую роль в этом играет анализ алиасов, который основан на обновляющих последовательностях. Далее используется редукция частичного порядка для построения графа транзакций. Она использует тот факт, что параллельные вычисления - это частично упорядоченные операции над разделяемыми данными. И нет необходимости анализировать все возможные варианты взаимодействия, реализующие конкретный частичный порядок. Два утверждения считаются зависимыми, если они обращаются к одной и той же области памяти и хотя бы один из доступов является записью. При построении графа транзакций вычисляются достижимые состояния одного из потоков до тех пор, пока не встретится обращение к разделяемой памяти. В таком случае проверяется, можно ли из текущих состояний других потоков достигнуть состояния, зависимого от данного. Если можно, то необходимо учесть переключение потоков и в граф добавляются соответствующие дуги. В противном случае продолжают вычисляться достижимые состояния для выбранного потока. Некоторые дуги могут быть выброшены из-за ограничений на примитивы синхронизации. 
По каждой дуге строятся проверки (asserts) для того, чтобы отсечь недостижимые пути. При этом формулы, построенные для разделяемых переменных, распространяются на все потоки. Полученные инварианты используется для доказательства недостижимости некоторых участков кода, содержащих разделяемые переменные. Это позволяет произвести уточнение графа транзакций и уменьшить количество рассматриваемых переключений. 
Оценка инструмента проводилась на 9 драйверах Linux с известными гонками. Сравнение проводилось между методом с генерацией формул и последующим уточнением и обычным методом без уточнения. При небольшом количестве разделяемых переменных (несколько штук) методы работают быстро и похожим образом. При двух десятках разделяемых переменных метод с уточнением работает в 20 раз медленнее, и время анализа составляет несколько минут. При этом, время работы слабо зависит от размера программы. Из 24 сообщений об ошибке, истинными оказались 21. При этом явно какое-то число потерялось, но не сказано какое. Трассы, построенные на основе полученных предупреждений, подавались на вход BMC, который пытался их доказать. В отдельных случаях, время доказательства занимало 10 часов. 

В статье ~\cite{Cohen:2009} авторы подходят к проблеме поиска доказательства для многопоточной программы с другой стороны. 
Для доказательства выполнения некоторого свойства многие инструменты проверки моделей вычисляют достижимые состояния и в каждом из них проверяют выполнение требуемого свойства. Другой подход заключается в локальном доказательстве. Для каждого из потоков записывается свой инвариант в терминах глобальных переменных и доказывается его корректность, а из конъюнкции всех инвариантов следует выполнимость необходимого свойства для целой программы. 
Главная проблема заключается в том, что не всякое доказательство может быть выражено через локальное. И в этом случае поиск локального доказательства будет бесконечным. Основное достижение данной статьи в том, что был предложен конечный метод для поиска локального доказательства. 
Алгоритм поиска доказательства основан на поиске неподвижной точки для предусловий, из которых следует требуемое свойство. Шаг алгоритма, на котором вычисляется следующее приближение для вектора локальных предусловий называется фазой уточнения. Если в процессе уточнения получена неподвижная точка, то есть вектор из предусловий равен тому, который был на предыдущем шаге, поиск доказательства заканчивается. Далее доказывается, что такой алгоритм корректен и конечен. 
Непонятно, на каком количестве и на каких тестах была произведена оценка алгоритма. Предлагаемый метод сравнивался с прямой и обратной (backward) проверкой моделей в полном пространстве состояний. Во многих тестах (со слов авторов) их подход показал хорошие результаты. 

Многие вышеперечисленные статьи оперируют понятием редукции частичных порядков. В статье ~\cite{Kahlon:2009} представлен новый подход к редукции частичных порядков, называемый монотонной редукцией. Он основан на новой характеристике частичного порядка, которая определяется через вычисления данной программы в терминах квазимонотонных последовательностей. Этот подход может быть использован и точным, и символическим методами проверки моделей. В статье показано, что ограничения на взаимодействие потоков, построенные на основе квазимонотонных последовательностей гарантируют и корректность, и полноту. 
Отношение независимости определяется, как возможность переставлять операции в двух потоках. Представляеются две стратегии: оптимальная частичная редукция частичных порядков и частичная редукция “дверного глазка” (peephole).
Для оценки результатов использовался модифицированный тест, известный как “обедающие философы”. Сравнение предлагаемого алгоритма производилось со стандартной стратегией BMC.

~\cite{Abdulla:2014:POPL, Abdulla:2014} - одно из развитий

В статье ~\cite{VCC:2009} авторы представляют верифицирующийемый Си компилятор (VCC), который интегрирован в Microsoft Visual Studio. Это полностью автоматическая система, которая может верифицировать аннотированные программы. Аннотации представляют собой инварианты, пред- и постусловия. VCC транслирует Си программу в язык Boogie, из аннотаций генерируются формулы логики первого порядка, которые разрешаются с помощью решателя Z3. Аннотации позволяют описывать инварианты на типы указателей, с которыми всегда возникают проблемы. 
Многие подходы к верификации параллельных программ основаны на том, что начинают доказательства с несвязанных состояний. Но в этом состоянии находится некоторая разделяемая часть, через которое происходит взаимодействие потоков. Синхронизация обеспечивается некоторыми встроенными объектами, например, спинлоками. Предлагаемый подход способен верифицировать реализацию структур данных, используемых для обеспечения синхронизации. Для этого необходимо записать инвариант на два состояния, в котором будет указано условие на атомарный доступ к данным. Аннотации позволяют сформулировать требования к модифицируемому объекту. 
В статье не представлен никакой алгоритм, просто рассказаны его преимущества и некоторые результаты. Инструмент был применен к Microsoft Hyper-V Server 2008 и тот был успешно проверифицирован. Для этого его разбили на 12 частей, каждую из которых верифицировали отдельно.

Похожая идея демонстрируется в статье ~\cite{Burnim:2009}, в которой представлен фреймворк для аннотации Java программ. Аннотации представляют пред- и постусловия для некоторых блоков кода, которые проверяются по ходу выполнения программы. Отличие от обычных пред- и постусловий заключается в том, что они пишутся для двух возможных вариантов выполнения этого блока. То есть, если для двух исходных состояний выполняется предусловие, то после выполнения двух соответствующих потоков будет выполнено постусловие. Это называется проверкой определенности (deterministic assert). Инструмент реализован ввиде бибилиотеки к Java. Поддерживается два встроенных предиката equals и approximateEquals. 
Проверки определенности легче писать, чем обыкновенные пред- и постусловия. 
Для оценки работы инструмента использовалось два набора тестов: Java Grande Forum (JGF) и Parallel Java (PJ) Library, в сумме 13 тестов 1000-4000 строк кода. В среднем потребовалось около 10 строк аннотаций, чтобы найти те же гонки, что и CalFuzzer. 

Статья ~\cite{Ganty:2009:POPL} посвящена проблеме проверки живучести асинхронных программ. Для представления программы используется обобщение графа потока управления, в котором присутствуют специальные дуги, соответствующие асинхронным вызовам. Формулируются проверяемые свойства. Завершаемость означает, что из каждой процедуры есть возврат и нет бесконечного запуска процедур. Второе свойство - неголодания (non-starvation) означает, что из каждой процедуры есть возврат, а при бесконечном выполнении все процедуры обрабатываются, то есть нет такой, выполнение которой постоянно откладывается. 
Доказательство этих двух свойств осложняется тем, что программа потенциально может содержать неограниченное количество вызовов функций, например, из-за рекурсии.
По асинхронной программе строится конечный автомат. Проверка завершаемости программы переформулируется в проверку некоторого свойства этого автомата. Далее показывается, что для любого автомата, можно построить автомат, не содержащий рекурсии, множество достижимых состояний которого совпадет с исходным. По такому автомату строится сеть Петри, на которой уже показывается выполнимость требуемого свойства завершаемости. Для сети Петри это означает, что не существует графа покрытия, как конечного автомата. Проверка этого условия сводится к проверки разрешимости формулы в арифметике Пресбургера. Так как каждый шаг алгоритмически разрешим, в итоге проверка свойства живучести программы алгоритмически разрешима. 
Статья крайне теоретизирована, и нет никаких экспериментов.

Очень интересная идея была описана в статье ~\cite{Leino:2009}. В ней представлен подход к верификации многопоточных программ, основанный на понятии разрешения. Так, поток имеет право на доступ к некоторой ячейке памяти, если у него есть на это разрешение, которое представляет вероятность от 0 до 100\% включительно. Значение 100\% означает эксклюзивный доступ на запись, любое число от 0 до 100 - доступ на чтение. Для каждой функции записывается предусловие, в котором указывается, какое значение для разрешения требуется для ее выполнения. Отдельно нужно заметить, что рассматриваются объектно-ориентированные программы, в которых синхронизация между потоков осуществляется с помощью мониторов. Мониторы представляют собой блокировки, которые используются для защиты от одновременного доступа некоторые области памяти. Во время создания нового объекта или захвата монитора для него разрешение устанавливается на 100\%. При доступе к объекту строится формула из ограничений и подается на вход решателю.
Никаких экспериментов не было проведено.

Слабые модели памяти! Например ~\cite{Zhang:2015:PLDI, Zhang:2015}

%\newpage
%============================================================================================================================

\section{Методы статического анализа многопоточных программ}
\label{rw:static}
Статический анализ традиционно применяется на больших программных системах, на которых нельзя провести формальную проверку моделей. Он отличается большим набором проверенных ситуаций, чем динамический анализ, но не может претендовать на формальное доказательство отсутствия ошибок.
В статье ~\cite{Yahav:2008} описывается фреймворк для доказательства корректности параллельных программ, которые динамически выделяют память. Он позволяет встраивать в себя различные алгоритмы доказательства для различных свойств безопасности. Семантика Java-программы описывается с помощью мета-языка, основанного на логике первого порядка. Далее, вычисляется аппроксимация множества достижимых состояний (обычно бесконечного). С помощью теории абстрактной интерпретации формулируются абстрактные состояния, которые представляют некоторое множество конкретных достижимых состояний. Для каждого оператора программы вычисляется эффект, или действие, которое представляет собой формулу логики первого порядка. Это является важным отличием от других инструментов проверки моделей, в которых используется логика высказываний.
Действие может изменить абстрактное состояние. При получении нового абстрактного состояния фреймворк проверяет, что оно удовлетворяет сформулированным свойствам безопасности. Таким образом, может быть получено ложное предупреждение о нарушении свойства, но оно никогда не будет пропущено.
Во фреймворке могут быть заданы следующие параметры:
1) что является конкретным состоянием;
2) как конкретные состояния абстрагируются;
3) семантика операторов, т.е. как операторы меняют абстрактное состояние;
4) определение свойств, которые необходимо проверять.
Можно выделить следующие основные особенности фреймворка.
1) Не требуется создание графа абстрактных состояний сразу для всей программы.
2) Абстрактное состояние представляют собой глобальное состояние программы, а не только взаимосвязь между выделенными областями памяти. Это позволяет комбинировать информацию о планировании потоков с информацией о динамически выделенной памяти.
3) Графы потока управления потоков представляются не раздельно, а собираются в одно глобальное состояние, что после абстрагирования потенциально позволяет рассматривать неограниченное количество потоков.
ESP[cite] и SLAM[cite] перед непосредственно верификацией программы проводят анализ указателей, результаты которого используются в дальнейшем. Такое разделение приводит к неточностям анализа. Описываемый фреймворк производит верификацию и анализ указателей одновременно, что позволяет повысить точность. Однако, было бы неверно сравнивать только точность без масштабируемости. С точки зрения практического использования и двухфазный подход, и интегрированный ограничены. В первом случае потеря точности не позволяет верифицировать многие свойства корректно, а второй подход не позволяет верифицировать реальные программы из-за большого размера. В будущем планируется применить некоторые техники для увеличения масштабируемости, такие как динамическая частичная редукция (dinamic partitial-order reduction) и стадийность (staging)[cite]. 
Фреймворк оценивался на восьми тестах. При наличиие ошибки в программе достаточно бывает нескольких десятков состояний. А для доказательства ее отсутствия приходится рассмотреть несколько тысяч. Самый большой тест занял около двух часов.

Статья ~\cite{Pratikakis:2011} представляет инструмент Locksmith для статического поиска гонок.
Locksmith реализован на основе библиотеки CIL[cite], которая используется для разбора исходного кода.
На первой фазе анализа происходит расстановка меток и создание ограничений (labeling and constraint generation). Locksmith обходит граф потока управления и создает две ключевые абстракции: ограничения потока меток (label flow constraints), чтобы смоделировать поток данных в программе, и ограничения потока управления (control flow constraints), чтобы смоделировать последовательность действий и связать ее с первым типом ограничений. Анализ потока меток чувствителен к полям структур (field-sensitive), это значит, что каждое поле моделируется независимо от других. Возникают различные проблемы с моделированием указателей типа void, и в статье было рассмотрено несколько вариантов их решения. Чтобы достигнуть контекстной чувствительности, информация о вызове функции добавляется в граф потока меток. Ограничения потока управления представляют собой граф потока управления каждого потока.
Следующая стадия называется анализ разделяемости данных, на которой определяются те области памяти, которые доступны из нескольких потоков. Для каждой операции вычисляется эффект - множество областей памяти, к которым происходит доступ. Будущий эффект (future effect) потока — это множество всех эффектов для каждой из операций. Пересечение будущих эффектов для потоков и дает множество разделяемых областей памяти.
Анализ захваченных блокировок идет параллельно предыдущему анализу. После каждой операции вычисляется множество захваченных блокировок.
Следующий шаг — вывод корреляции (correlation inference). В этот момент пересекаются множества захваченных блокировок для каждого доступа к разделяемой переменной. Это центральный момент анализа, после которого возможен вывод предупреждений или применение дополнительных эвристик.
Locksmith запускался на шести приложениях с использованием POSIX потоков и на девяти драйверах ОС Linux. Для POSIX приложений время анализа мало меняется и составляет около 0.5 с на 1000 строк кода. Для драйверов это время в среднем составляет 1с на 1000 строк кода, но в отдельных случаях возрастает до 60 с на 1000 строк кода. Для POSIX приложений число истинных ошибок составляет 29\% от числа ложных срабатываний, для драйверов — 9\%. Большинство ложных срабатываний связано с неточноностью анализа разделяемых данных.

Статья ~\cite{Kahlon:2009:SDR} посвящена проблеме построения графа потока управления для многопоточной программы, если в ней имеются вызовы по функциональным указателям, а также проблеме анализа алиасов в этом случае. Программа должна быть написана в соответствии с моделью fork-join[cite]. Для нее строится параллельный граф потока управления, который представляет собой обычный ГПУ для каждого из создаваемых потоков. 
Далее рассматривается идея бутстрепинга[cite] для быстрого определения множества алиасов. Она основана на разбиении Стинсгаарда[cite] применительно к алиасам. Так, указатели могут быть алиасами указателей только из своего подмножества. Идея заключается в том, чтобы не следить за присваиванием всех возможных пар указателей, а только за теми, которые относятся к своему классу эквивалентности. Вторым важным понятием являются обновляющие последовательности - это последовательность присваиваний, которая обновляет указатель. Соответственно, p и q могут быть алиасами, только если существует обновляющая последовательность от p к q. Так как разбиение Стинсгаарда обычно невелико, то строить обновляющие последовательности, чтобы доказать корректность алиасов, приходится нечасто. 
Отдельно рассматривается вопрос о рекурсии. Граф потока управления раскручивается до тех пор, пока не будет найдена неподвижная точка в терминах разбиения Стинсгаарда. Полученный граф состояний обходится и анализируется на предмет наличия состояний гонки с помощью стандартного алгоритма Lockset. Разделяемые переменные определяются, как алиасы к глобальным переменным. Что будет со списками пока непонятно. Рассматриваются три модели потоков. Первая - самая простая, в которой считается, что каждая функция может выполняться параллельно с каждой. Вторая модель - fork-join, в которой параллельность начинается с ключевого слова fork и заканчивается после join. Третья модель отличается от предыдущей отсутствием точек join и ограничением на количество задач на одном потоке. Это приводит к тому, что некоторые ситуации гонки оказываются невозможны. Инструмент проверялся на нескольких драйверах OC Linux,  алгоритме параллельного сжатия bzip2smp, параллельном MPEG декодере и некотором параллельном продукте. На небольших программах инструмент работал несколько секунд. Порядок количества предупреждений совпадал с порядком числа разделяемых переменных. Отдельный запуск на большой системе занял 22 минуты. Однако, разделяемых переменных было всего 4, поэтому количество предупреждений оказалось невелико. 

Проблема анализа алиасов по-своему решается в статье ~\cite{Seidl:2009}.
Цель анализа регионов - показать, что выделенная на куче память корректно разделена на непересекающиеся блоки.  Первый подход основан на сложном анализе размера структур данных. Этот подход очень плохо масштабируется на большие программы. Другой подход работает с динамически выделенными объектами, как с блоками памяти, связанными с абстрактными состояниями. В этом случае возникают проблемы с анализом областей памяти, выделенных в одной точке программы. В статье описан анализ регионов достаточно быстрый и точный для программ, работающих с непересекающимися областями памяти. Данный анализ может быть расширен до метода поиска гонок с использованием стандартного алгоритма Lockset. 
Две глобальных переменных считаются эквивалентны, если доступ к некоторой ячеки памяти можно получить и через первую переменную, и через вторую. Анализ хранит информацию об эквивалентности переменных для каждой точки программы. Кроме того, хранится для каждого локального указателя хранится множество областей памяти, куда он может указывать, т.н. may-алиасы. Для поиска гонок отдельно собираются must-алиасы для указателей на блокировки. 
Данный анализ может быть расширен для обработки массивов. Так, каждый элемент массива считается отдельной переменной. Если индекс массива участвует в операциях сложения и вычитания, анализ будет выполнен корректно. При присваивании в него результата другой операции, соответствующая информация о всех элементах массива удаляется, так как неясно, в какой именно элемент происходит доступ. 
При применении инструмента к модулям ОС Linux авторы столкнулись с проблемами обработки структур, содержащих массивы, арифметикой указателей, преобразованием типов (кастированием). Были попытки расширить возможности анализа, например, предположением, что указатель может указывать не только на начало блока памяти. 
Инструмент запускался на 9 драйверах. Время работы составляло в среднем 1-2 секунды. Число разделяемых переменных оказалось невелико, не больше 5.

Зачастую инструменты статического анализа нацеливаются на эффективный поиск некоторого класса ошибок. Например, в статье ~\cite{Naik:2009} представлен алгоритм поиска состояний взаимной блокировки для Java программ. Инструмент производит k-объектный, контекстно-чувствительный анализ исходного кода, строит граф вызовов и граф указателей (points-to). Выделяются все возможные места, в которых возможна блокировка, то есть состояния, в которых захвачены некоторые блокировки и ожидается их освобождение. После чего применяется ряд фильтров:
1) Состояния должны быть достижимы.
2) Должно быть показано, что блокировки действительно парные. То есть, либо их точное равенство, либо возможность быть алиасами.
3) Должно быть показано, что не возможно освобождение блокировки из другого потока. 
4) Возможность параллельной блокировки, то есть возможность оказаться двум потокам одновременно в соответствующих состояниях.
5) Блокировки должны быть разными, то есть встречается перезахват одной и той же блокировки. Это требует точного анализа алиасов (must-aliases).
6) Отсутствие общей блокировки. Для того чтобы предотвратить взаимную блокировку, возможен захват некоторой общей.
Инструмент проверялся на наборе тестов, доступном на http://chord.stanford.edu/deadlocks.html Размеры тестов составляли в среднем 100 000 операторов (locations), содержали несколько сотен классов. Время анализа составляло около 10 минут. Важно замететить, что алгоритм является неточным. Первое ограничение в том, что поиск взаимных блокировок ведется между парами потоков. Большее количество не учитывается. Второе важное ограничение - это учет синхронизации только на основе блокировок.

Очень интересна работа ~\cite{Xiong:2010}, которая посвящена поиску неявных типов синхронизаций.
В статье проведен анализ нескольких больших программных продуктов на предмет наличия в них неявнных или специальных (ad hoc) видов синхронизации, например, таких как ожидание в цикле, пока некоторая переменная не примет определенное значение. Важно заметить, что если в программе определяется некоторая функция, которая используется для синхронизации, она не считается неявной.
В процессе исследования были получены следующие результаты.
1) Каждая изученная параллельная программа использует неявную синхронизацию. 
Процент очень сильно варьируется от 6-83%.
2) В основном, все неявные типы синхронизации представляют собой бесконечные циклы, выход из которых возможен при специальном условии. Но несмотря на это, такие неявные синхронизации тяжело определять.
3) В 22-67\% случаях неявный способ синхронизации приводил к ошибкам. Обычно это выражалось во взаимной блокировке или зависанию системы. 
4) Из-за того, что многие инструменты не могут определить неявную синхронизацию, пропускается большое число ошибок. 
Для помощи разработчикам был создан инструмент, который аннотирует синхронизационные циклы. Его алгоритм заключается в следующем. Сначала он выделяет все циклы. Далее, изучает условия, при которых происходит выход из цикла и определяет те, в которых переменные могут быть доступны другому потоку. В большинстве случаев, условие при синхронизации является инвариантом цикла с тем, чтобы переменная была обновлена из другого потока. После таких проверок определяется множество циклов, которые могут быть использованы для синхронизации. Далее, выполняется поиск парной операции, которая обновляет переменную, участвующую в условии цикла. Инструмент сделан на основе LLVM  компилятора и переиспользует его промежуточное представление. Были попытки учета значения, которое записывается в разделяемую переменную, с тем, чтобы, используя SAT решатель, формально показать, что цикл является неявной синхронизацией, однако этот подход оказался слишком тяжеловесным. Обычно в такую переменную явно присваивается число, при том один раз, проверяется также обычно на равенство конкретному значению, поэтому можно использовать более простые техники, чем решатели. В инструменте используется распространение ограничений. 
В результате каждый найденный синхронизационный цикл аннотируется. Такой результат может быть использован в двух аспектах. Во-первых, разработчики могут вручную просмотреть каждый цикл и понять, является ли он ошибкой или нет. На проведенных тестах инструмент верно нашел 96\% неявных способов синхронизации. При этом число ложных сообщений об ошибках было всего 6\%. Во-вторых, другие инструменты поиска гонок могут использовать данные аннотации для более точного анализа. Так, эксперименты с Valgrind показали, что число ложных предупреждений сокращается на 43-86\%. 

%\newpage
%============================================================================================================================

\section{Методы динамического анализ многопоточных программ}
\label{rw:dynamic}

Динамический анализ активно применяется для поиска частовозникающих ошибок, его основное достоинство заключается в том, что его процент ложных срабатываний значительно меньше, чем у статического. 
Рассмотрим основные инструменты динамического анализа, предназначенные для поиска состояний гонок. Все они используют идею векторных часов Лампорта и некоторые оптимизации для того, чтобы сократить накладные расходы. В основном, она заключается в сэмплинге (sampling), то есть в уменьшении объема памяти, за которой производится слежение.
В статье ~\cite{Flanagan:2009:PLDI, Flanagan:2009} описывается инструмент динамического поиска гонок в Java программах. Он основан на методе векторных часов Лампорта. Но так как запись всех действий в программе занимает слишком много времени, то сохраняются только самые последние доступы к переменной. Менее 1\% случаев гонок требуют полного сохранения векторных часов, в остальных случаях достаточен более легковесный подход. Используется понятие эпоха - это идентификатор векторных часов и номер потока. Инструмент позволяет адаптивно выбирать, сохранять ли конкретное значение векторных часов для некоторой переменной или только эпоху. Такой подход позволяет уменьшить накладные расходы, не потеряв точности.  
Состояние потока включает в себя векторные часы, значение векторных часов для освобождаения каждой блокировки, эпоху или вектор часов для последнего чтения каждой переменной и эпоху последней записи в каждую переменную. 
Если происходит чтение переменной, оно обрабатывается следующим образом. Если предыдущее чтение было сделано в ту же эпоху, то ничего не происходит. Если для переменной сохранен вектор часов, то просто обновляются его компоненты. Если чтение происходит в другую эпоху, то сохраняется новое значение эпохи. Операция записи в переменную обрабатывается похожим образом. Обновляется информация о текущей эпохе. Кроме того, проверяется информация о чтении соответствующей переменной и в случае необходимости выдается предупреждение об ошибке.
Инструмент сравнивался со множеством других аналогичных детекторов на 16 тестах. Все предупреждения были выданы для инстинных ошибок. Требуемое для анализа время, в среднем, в 4-5 раз больше, чем для работы исходной программы. Другие инструменты, основанные на том же методе векторных часов в отдельных случаях увеличить время работы в 300 раз. Объем требуемой памяти возрастает на 20-30\%.

В статье ~\cite{Sadowski:2009} представлен инструмент для динамической проверки в Java программах двух свойств:
1) Отсутствие конфликтов между потоками внутри одной транзакции.
2) Потоки внутри транзакции не должны влиять на потоки вне ее. 
Для проверки первого условия используется алгоритм векторных часов, который строит отношение happens-before внутри транзакции. Для проверки второго условия тот же самый граф happens-before строится для транзакций в целом. 
Конфликтом называется ситуация, в которой происходит обращение к одним и тем же данным из разных потоков или захват/освобождение одной и той же блокировки. Кроме того, к конфликтам относятся операции в потоке до его создания (fork) или после завершения (join). Транзакцией является некоторая последовательность операций. 
Инструмент принимает на вход Java байткод. Он был проверен на восьми тестах JavaGrande, каждый тест был размером около 1000 строк кода. Замедление времени работы составило около 10 раз. 

В статье ~\cite{Marino:2009:PLDI, Marino:2009} представлен инструмент для динамического поиска гонок. Он основан на гипотезе “холодных регионов”: предполагается, что состояния гонки, скорее всего, проявятся в редко исполняемых участках кода, так как на часто исполняемых они уже исправлены. При таком предположении можно уменьшить количество памяти, за которой происходит слежение. Каждый раз исполняя код, его уровень сэмплинга уменьшается, таким образом, за горячими участками слежение почти не ведется, а доступы к памяти из холодных участков отслеживаются полностью. Важное отличие инструмента в том, что уровень сэмплинга локальный, то есть отдельный для каждого из потоков.
Инструмент строит отношения happens-before для всех операций. Если для двух доступов к памяти невозможно указать порядок, то есть, построить отношение happens-before, выдается предупреждение о возможном состоянии гонки. 
Перед инструментом ставится две цели: невысокое увеличение накладных расходов и отсутствие ложных предупреждений. Если не обрабатывать все операции с примитивами синхронизации, можно потерять happens-before дуги, и это приведет к ложному сообщению об ошибке. Таким образом, можно управлять только уровнем слежения за доступами к памяти. Все операции логируются, поэтому каждое предупреждение можно проверить вручную, является ли оно реальной ошибкой или нет.
Были исследованы различные алгоритмы сэмплинга: адаптивный локальный, фиксированный локальный, глобальный адаптивный, случайный и др. В среднем, по результатам запуска инструмента на девяти программных системах лучшие результаты показывают алгоритмы с локальном уровнем сэмплинга. В среднем, накладные расходы составляют 28\% времени работы, хотя в некоторых случаях достигают 100\%. Это в 25 раз меньше, чем если бы обрабатывались все обращения к памяти, то есть при уровене сэмплинга в 100\%.

Статья~\cite{Bond:2010:PLDI,Bond:2010} представляет еще один инструмент - PACER.
Кратчайшим состоянием гонки называется если до этого не встретилось другого доступа к той же самой памяти. То есть, инструмент сообщает о первом же нарушении. Состояние гонки - выборное(sampled), если оно произошло в период выборки (sampling period). Инструмент Pacer обнаруживает выборанные кратчайшией состояния гонки и дает гарантии того, что существующая гонка будет найдена с вероятностью равной уровню выборки (sampling rate). Инструмент основан на алгоритме векторных часов, который строит отношение happens-before для все операций. Ключевые моменты, на которых основано снижение накладных расходов, следующие. 
1) Во время периода, когда слежениея за памятью не производится, (non-sampling period) кратчайшее состояние гонки не может быть найдено, это экономит память и время.
2) В это же время нет необоходимости увеличивать параметр векторных часов, что также позволяет экономить ресурсы.
В итоге для уровня выборки от 1-3\% накладные расходы составляют 52-83\%.
Однако метод выбора объектов слежения имеет два важным недостатка:
1) Можно пропустить важные happens-before дуги, которые приведут к ложному предупреждению.
2) При уровне выборки r число найденных состояний гонок будет лишь r2. 
LiteRace инструментирует все опеирации синхронизации, чтобы решить первую проблему. Для решения второй он ищет состояния гонок только в холодных участках кода. Еще важное отличие LiteRace в том, что он детерминирован, а Pacer намеренно использует случайные значения, чтобы найти состояния гонки, которые были пропущены в предыдущих запусках.
Pacer случайно включает и выключает слежение за динамическими операциями (sampling period). Во время слежения он автоматически подбирает уровень слежения (sampling rate) такой, чтобы вероятная ошибка нашлась с заданной вероятностью. Во время периода слежения, Pacer обрабатывает все операции, связанные с синхронизацией, и все доступы к переменным. В оставшееся время, инструмент следит только за теми переменными, которые он выбрал.
Для оценки использовались 4 набора тестов, на каждом из которых было сделано 50 запусков. Ошибки, проявившиеся хотя бы на половине из запусков, составляют около трети от числа тех, которые проявились хотя бы на одном.

Статья ~\cite{Serebryany:2011} представляет улучшение метода, реализованного в инструменте ThreadSanitizer-Valgrind[cite], представленного ранее. Основная часть логики метода осталась той же самой, однако в следствие использования компилятора LLVM удалось повысить скорость работы, а также портируемость, с которой были большие проблемы. 
TSan-LLVM использует инструментацию во время выполнения программы, что приводит к замедлению ее работы в 2-3 раза. Сам алгоритм анализа может быть представлен в виде конечного автомата, который обрабатывает произошедшие в программе события, такие как чтение, запись, захват блокировки и др. Для определения состояния гонки используется и Lockset алгоритм, и Happens-Before, что позволяет повысить точность. 
Инструментация производится на уровне промежуточного представления LLVM. Она необходима для того, чтобы собирать информацию о стеке вызовов функций, а также о доступах к памяти. 
Для того, чтобы уменьшить расходы на анализ, применяется выборочное слежение за доступами к памяти (sampling). Для этого была принята гипотеза о том, что состояния гонки, скорее, встретится в “холодных” функциях, потому что в часто используемых областях состояния гонки либо уже исправлены, либо неопасны. В отличие от LiteRace, который применяет ту же идею, TSan всегда выполняет инструментированный код, но если для данного потока счетчик выполнений данной операции выше уровеня упрощения (sampling rate), то информация о доступе к памяти игнорируется. Второе важное отличие заключается в том, что LiteRace считает холодными участками кода целые функции, TSan оперирует на уровне базовых блоков, что уточняет анализ.
Основной недостаток инструментации во время выполнения - это то, что могут быть потеряны ошибки, находящиеся в коде, которые не компилируется: системные библиотеки или JIT код. 
Сравнение подхода показало, что, в среднем, применение инструментации позволяет ускорить работу в 2-3 раза по сравнению с оригинальным TSan-Valgrind и в 10 раз по сравнению с другими инструментами, такими, как Valgrind. Однако, не сравнивалось число найденных ошибок. 

Также, как и статические методы, динамические инструменты могут быть нацелены на конкретные классы ошибок. В статье~\cite{Park:2009:ASPLOS,Park:2009:SIGARCH,Park:2009} описывается подход к динамическому поиску конкретного класса ошибок в многопоточных программах - нарушениям атомарности операций. Чтобы уменьшить объем анализируемых данных, все возможное множество вариантов переключения контекста ограничивается теми, которые соответствуют несериализуемым взаимодействиям (unserializable interleavings). Для таких взаимодействий не существует никакого последовательного эквивалента выполнения участвующих операций. Из этого множества нужно исключить невыполнимые варианты взаимодействия, например, защищенные одной и той же блокировкой. Инструмент умеет определять часто возникающие ситуации и фокусируется на редких. Анализ делится на несколько стадий. Сначала запускаются несколько тестов для профилирования, затем определяются все возможные нарушения атомарности, после чего выделяются достижимые. Далее, полученное множество упорядочивается по частоте возникновения.
Инструмент запускался на таких промышленных программных системах, как MySQL, Apache, Mozilla и др. Затраченное время на анализ оказалось в 10-1000 раз меньше, чем у других подходов. 

В статье ~\cite{DataCollider} представлен оригинальный способ поиска гонок в ядре ОС.
Одна из проблем поиска гонок в ядре операцонной системы заключаются в том, что ядро ОС оперирует более низким уровнем абстракции, чем пользовательские приложения. Вторая важная особенность - это проблема поиска состояния гонки в случае, когда обращение к данным происходит от аппаратуры. И, наконец, многие динамические инструменты значительно замедляют работу программы. К К тому же они используют инструментацию, которую довольно сложно применить к ядру ОС. 
DataCollider расставляет несколько точек прерывания на случайные доступы к памяти. Когда программа доходит до них, выполнение останавливается, сохраняется значение той ячейки памяти, куда происходит обращение, и спустя какое-то время проверяет, что значение не изменилось. В ином случае фиксируется состояние гонки. Для того чтобы получить информацию о потоке, из которого произошел второй доступ к памяти, используются аппаратные прерывания, которые ставятся на доступ к конкретной области памяти. Значительное преимущество инструмента состоит в том, что нет необходимости разбираться в сложных примитивах синхронизации ядра.
Не все состояния гонки ведут к ошибкам. Так, эксперименты с DataCollider показали, что только 10\% предупреждений соответствует истинным ошибкам. Чтобы уменьшить число ложных предупреждений используется некоторая обработка информации после анализа.
Для определения точек расстановки прерываний DataCollider дезассемблирует исполняемый файл и получает множество всех областей памяти. Далее, используя простые алгоритмы статического анализа, он отсеивает те локальные области памяти, доступ к которым никак не может привести к состоянию гонки. Из оставшихся выбираются те, за которыми будет следить инструмент, и на них расставляются точки прерываний. В случае, если во время работы инструмента была найдена ошибка, то соответствующая ей точка прерывания удаляется и выбирается новый доступ к памяти. Во время работы DataCollider следит за количеством прохождений выбранных точек прерываний. Если оно больше или меньше, чем некоторое целевое значение, точка останова может быть удалена, и выбрана новая.
DataCollider был применен к нескольким драйверам ОС Windows. Было найдено 38 состояний гонки. При этом замедление работы было всего 10-15\% процентов. 

В статье ~\cite{Fonseca:2010} представлен анализ ошибок, исправленных в сервере MySQL в процессе разработки от версии 3.x до версии 6.х. Все исправления (12500 коммита) были отфильтрованы по ключевым словам, относящимся к параллельному выполнению (concurrent, atomic, lock, synchronization и др). Из этого множества (583 ошибки) были исключены те ошибки, описание которых было недостаточно ясное (347 ошибок). После чего были выбраны некоторые из этих ошибок, которых оказалось 80, и проанализированы вручную.  
Результаты показали, что ошибки, связанные параллельным выполнением становятся все более и более распространенными. Состояние взаимной блокировки вызывали 40\% ошибок. 28\% всех ошибок приводили к падению системы, а 15\% - к предоставлению неверных данных пользователю. 15\% всех багов приводили к ошибки не сразу, т.н. “скрытые” баги, причем 92\% из них впоследствии проявляют себя тем, что выдают пользователю невереные данные - это семантические баги. Эта категория была проанализирована более детально. Больше половины из семантических багов (58\%) нарушала порядок выполняемых транзакций. 25\% багов нарушали свойство изолированности транзакций. Ключевые структуры данных, которые повреждались при скрытых багах следующие: файлы с данными, с индексами и с определениями, кэши запросов и ключей, лог. 
На нахождение ошибок в среднем уходило 3-4 месяца после ее внесения. Для поиска ошибок, вызывающих повисание системы требовалось до 7 меяцев.
Далее, в статье ~\cite{Fonseca:2011} авторы рассказывают о своем опыте поиска гонок в MySQL сервере.
Сначала вводится понятие истории - конечной последовательности событий, которые могут быть либо вызовом операции, либо ее ответом. История индуцирует частичный порядок на множестве событий: операция о1 происходит раньше о2, если ответ операции о1 происходит раньше, чем начало выполнения о2. Далее, определяется линеаризуемость. История событий в параллельной системе линеаризуема, если существует история событий последовательной системы, для которой порядок событий не нарушается. Это означает, что несмотря на внутренний параллелизм, сервер ведет себя так, как если бы все запросы выполнялись последовательно. 
Метод тестирования основан на том, что каждое параллельное выполнение сравнивается со всеми возможными его линеаризациями. Если ни одна из них не соответствует реальной трассе, фиксируется ошибка. 
Для того, чтобы найти скрытые ошибки, которые повреждают структуру данных, а не логику выполнения, необходимо применить описанный метод не в конце выполнения, а для каждого внутреннего состояния программы. Отдельный вопрос, как понять и описать это состояние. Это задача тестировщика, либо разработчика, который должен явно указать, что считать состоянием. Для этого они должны реализовать функцию суммирования состояния (state summary function), которая предоставляет ту информацию, которая в дальнейшем считается описанием состояния программы. Была реализована некоторая библиотека, которая позволяет упростить написание такой функции. В процессе выпуска новых версий программы ее логика не меняется, поэтому уже функции суммирования нужно написать единственный раз.
Традиционный подход к динамическому анализу многопоточных программ основан на стрессовом тестировании и генерации шума. Однако он имеет три ограничения. Во-первых, этот подход не систематичен, то есть не позволяет избежать анализа лишних или похожих событий. Во-вторых, в таком подходе невозможно выделить приоритетные события, которые, скорее всего, приведут к ошибке. И, наконец, даже если ошибка обнаружена, ее крайне сложно воспроизвести.
Инструмент PIKE пытается обойти эти ограничения с помощью алгоритма случайного планирования. При старте программы планировщик выбирает случайный приоритет для каждого потока. В каждый момент времени активен поток с наибольшим приоритетом. Приоритет случайным образом меняется в некоторых случайных точках программы. 
Для оценки результатов анализировался MySQL сервер, развернутый на кластере из 15 машин. Было проведено 1550 тестов, на каждом из которых было исследовано до 400 различных переключений контекста, используя описанный алгоритм планирования. Это заняло более месяца, однако имеются варианты ускорения тестирования, такие как метод мгновенного снимка (snapshotting), который позволяет сэкономить время на инициализацию сервера. Были найдены две ошибки, которые могли вызывать падение сервера, и 10 ошибок, которые приводили к некорректной работе сервера.
Примерно треть всех тестов привела к ложным предупреждениям об ошибках, однако, оказалось, что большинство из них связано с работой с различными кэшами. При параллельном доступе к кэшу по одному ключу, программа считает всю запись недействительной. Но это не приводит к ошибке, лишь к увеличению времени работы. Однако, инструмент выдает предупреждение об ошибке. Чтобы это обойти, было написано несколько фильтров к различным кэшам, которые проверяют, что в при линеаризованном запросе состояние (в данном случае, кэш) включает в себя состояние параллельного запроса, и в этом случае не выдается предупреждение.

Статья ~\cite{Vafeiadis:2010} посвящена понятию линеаризуемости.
Линеаризуемость - это свойство корректности параллельных реализаций абстрактных структур данных (стек, очередь, и др.). Оно требует, чтобы каждая операция была атомарна и удовлетворяла заданной функциональной спецификации. Один из способов доказать линеаризуемость - это определить точки линеаризации программы, в которых сосредаточена основная функциональность.
Предполагается, что программа состоит из некоторой части с инициализацией, после которой идет параллельное выполнения некоторого ограниченного, но заранее неизвестного числа потоков. Состояние программы включает в себя глобальные переменные и локальные переременные для каждого потока вместе со счетчиком команд.
В статье было выдвинуто наблюдение, что операции имеют сложные условные точки линеаризации, если их выполнение не меняет состояния программы. В таком случае выполнение называется свободным (pure), а иначе - эффективным. Для доказательства линеаризации для каждого метода вводится массив can\_return, который содержит true, если для конкретного потока и выполняемого при конкретном возвращаемом значении этого метода была достигнута точка линеаризации, и глобальное состояние этой программы не изменилось.
Для каждой операции (метода) в проверяемом классе пишется спецификация в терминах абстрактных состояний. В каждой спецификации выделяются пути ее выполнения. Для каждого пути строятся проверки чистой линеаризации (pure linearizability checkers). Они представляют собой присваивание в уже упомянутый массив can\_return true в случае, если на рассматриваемом пути не происходит изменения глобальной переменной. Если на пути происходит запись в глобальную переменную, операция считается эффективной, и точка линеаризации соответствует присваиванию в глобальную переменную. В соответствии со спецификацией инструментируется исходный код метода. Так, во время присваивания в глобальную переменную проверяется, что в метапеременной, хранящий результат вызова этого метода, еще ничего не записано. А в конце выполнения проверяется, что либо возвращаемый результат равен тому, что хранит эта метапеременная, то есть достигнута эффективная точка линеаризации, либо в массиве can\_return на соответствующем месте стоит true, то есть достигнута чистая точка линеаризации. Если проверка проходит неуспешна, фиксируется ошибка.
Инструмент был проверен на восьми тестах, в среднем каждый занимал 100 строк кода. 

Сошлёмся на приложения: Приложение \ref{AppendixA}, Приложение \ref{AppendixB2}.

Сошлёмся на формулу: формула \eqref{eq:equation1}.

Сошлёмся на изображение: рисунок \ref{img:knuth}.

%\newpage
%============================================================================================================================

\section{Формулы} \label{sect1_3}

Благодаря пакету \textit{icomma}, \LaTeX~одинаково хорошо воспринимает в качестве десятичного разделителя и запятую ($3,1415$), и точку ($3.1415$).

\subsection{Ненумерованные одиночные формулы} \label{subsect1_3_1}

Вот так может выглядеть формула, которую необходимо вставить в строку по тексту: $x \approx \sin x$ при $x \to 0$.

А вот так выглядит ненумерованая отдельностоящая формула c подстрочными и надстрочными индексами:
\[
(x_1+x_2)^2 = x_1^2 + 2 x_1 x_2 + x_2^2
\]

При использовании дробей формулы могут получаться очень высокие:
\[
  \frac{1}{\sqrt{2}+
  \displaystyle\frac{1}{\sqrt{2}+
  \displaystyle\frac{1}{\sqrt{2}+\cdots}}}
\]

В формулах можно использовать греческие буквы:
\[
\alpha\beta\gamma\delta\epsilon\varepsilon\zeta\eta\theta\vartheta\iota\kappa\lambda\\mu\nu\xi\pi\varpi\rho\varrho\sigma\varsigma\tau\upsilon\phi\varphi\chi\psi\omega\Gamma\Delta\Theta\Lambda\Xi\Pi\Sigma\Upsilon\Phi\Psi\Omega
\]

\def\slantfrac#1#2{ \hspace{3pt}\!^{#1}\!\!\hspace{1pt}/
  \hspace{2pt}\!\!_{#2}\!\hspace{3pt}
} %Макрос для красивых дробей в строчку (например, 1/2)
Для красивых дробей (например, в индексах) можно добавить макрос
\verb+\slantfrac+ и писать $\slantfrac{1}{2}$ вместо $1/2$.
%\newpage
%============================================================================================================================

\subsection{Ненумерованные многострочные формулы} \label{subsect1_3_2}

Вот так можно написать две формулы, не нумеруя их, чтобы знаки равно были строго друг под другом:
\begin{align}
  f_W & =  \min \left( 1, \max \left( 0, \frac{W_{soil} / W_{max}}{W_{crit}} \right)  \right), \nonumber \\
  f_T & =  \min \left( 1, \max \left( 0, \frac{T_s / T_{melt}}{T_{crit}} \right)  \right), \nonumber
\end{align}

Выровнять систему ещё и по переменной $ x $ можно, используя окружение \verb|alignedat| из пакета \verb|amsmath|. Вот так: 
\[
    |x| = \left\{
    \begin{alignedat}{2}
        &&x, \quad &\text{eсли } x\geqslant 0 \\
        &-&x, \quad & \text{eсли } x<0
    \end{alignedat}
    \right.
\]
Здесь первый амперсанд (в исходном \LaTeX\ описании формулы) означает выравнивание по~левому краю, второй "--- по~$ x $, а~третий "--- по~слову <<если>>. Команда \verb|\quad| делает большой горизонтальный пробел.

Ещё вариант:
\[
    |x|=
    \begin{cases}
    \phantom{-}x, \text{если } x \geqslant 0 \\
    -x, \text{если } x<0
    \end{cases}
\]

Кроме того, для  нумерованых формул \verb|alignedat|  делает вертикальное
выравнивание номера формулы по центру формулы. Например,  выравнивание компонент вектора:
\begin{equation}
 \label{eq:2p3}
 \begin{alignedat}{2}
{\mathbf{N}}_{o1n}^{(j)} = \,{\sin} \phi\,n\!\left(n+1\right)
         {\sin}\theta\,
         \pi_n\!\left({\cos} \theta\right)
         \frac{
               z_n^{(j)}\!\left( \rho \right)
              }{\rho}\,
           &{\boldsymbol{\hat{\mathrm e}}}_{r}\,+   \\
+\,
{\sin} \phi\,
         \tau_n\!\left({\cos} \theta\right)
         \frac{
            \left[\rho z_n^{(j)}\!\left( \rho \right)\right]^{\prime}
              }{\rho}\,
            &{\boldsymbol{\hat{\mathrm e}}}_{\theta}\,+   \\
+\,
{\cos} \phi\,
         \pi_n\!\left({\cos} \theta\right)
         \frac{
            \left[\rho z_n^{(j)}\!\left( \rho \right)\right]^{\prime}
              }{\rho}\,
            &{\boldsymbol{\hat{\mathrm e}}}_{\phi}\:.
\end{alignedat}
\end{equation}

Ещё об отступах. Иногда для лучшей <<читаемости>> формул полезно
немного исправить стандартные интервалы \LaTeX\ с учётом логической
структуры самой формулы. Например в формуле~\ref{eq:2p3} добавлен
небольшой отступ \verb+\,+ между основными сомножителями, ниже
результат применения всех вариантов отступа:
\begin{align*}
\backslash! &\quad f(x) = x^2\! +3x\! +2 \\
  \mbox{по-умолчанию} &\quad f(x) = x^2+3x+2 \\
\backslash, &\quad f(x) = x^2\, +3x\, +2 \\
\backslash{:} &\quad f(x) = x^2\: +3x\: +2 \\
\backslash; &\quad f(x) = x^2\; +3x\; +2 \\
\backslash \mbox{space} &\quad f(x) = x^2\ +3x\ +2 \\
\backslash \mbox{quad} &\quad f(x) = x^2\quad +3x\quad +2 \\
\backslash \mbox{qquad} &\quad f(x) = x^2\qquad +3x\qquad +2
\end{align*}


Можно использовать разные математические алфавиты:
\begin{align}
\mathcal{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber \\
\mathfrak{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber \\
\mathbb{ABCDEFGHIJKLMNOPQRSTUVWXYZ} \nonumber
\end{align}

Посмотрим на систему уравнений на примере аттрактора Лоренца:

\[ 
\left\{
  \begin{array}{rl}
    \dot x = & \sigma (y-x) \\
    \dot y = & x (r - z) - y \\
    \dot z = & xy - bz
  \end{array}
\right.
\]

А для вёрстки матриц удобно использовать многоточия:
\[ 
\left(
  \begin{array}{ccc}
  	a_{11} & \ldots & a_{1n} \\
  	\vdots & \ddots & \vdots \\
  	a_{n1} & \ldots & a_{nn} \\
  \end{array}
\right)
\]


%\newpage
%============================================================================================================================
\subsection{Нумерованные формулы} \label{subsect1_3_3}

А вот так пишется нумерованая формула:
\begin{equation}
  \label{eq:equation1}
  e = \lim_{n \to \infty} \left( 1+\frac{1}{n} \right) ^n
\end{equation}

Нумерованых формул может быть несколько:
\begin{equation}
  \label{eq:equation2}
  \lim_{n \to \infty} \sum_{k=1}^n \frac{1}{k^2} = \frac{\pi^2}{6}
\end{equation}

Впоследствии на формулы (\ref{eq:equation1}) и (\ref{eq:equation2}) можно ссылаться.

Сделать так, чтобы номер формулы стоял напротив средней строки, можно, используя окружение \verb|multlined| (пакет \verb|mathtools|) вместо \verb|multline| внутри окружения \verb|equation|. Вот так:
\begin{equation} % \tag{S} % tag - вписывает свой текст 
  \label{eq:equation3}
    \begin{multlined}
        1+ 2+3+4+5+6+7+\dots + \\ 
        + 50+51+52+53+54+55+56+57 + \dots + \\ 
        + 96+97+98+99+100=5050 
    \end{multlined}
\end{equation}

Используя команду \verb|\labelcref| из пакета \verb|cleveref|, можно
красиво ссылаться сразу на несколько формул
(\labelcref{eq:equation1,eq:equation3,eq:equation2}), даже перепутав
порядок ссылок \verb|(\labelcref{eq:equation1,eq:equation3,eq:equation2})|.

