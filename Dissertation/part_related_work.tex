\chapter{Обзор}
\label{chapter_related_work}

\section{Введение}
\label{rw:introduction}

% Разделить Java и Си?

Существует много разных направлений развития инструментов. 
Есть несколько причин, почему до сих пор сохраняется такое разнообразие техник.
\begin{enumerate}
\item Различные требования качества к инструментам.
\item Пока не существует метода, который показал бы себя эффективным в общем случае. 
\item Нет ясного способа сравнения подходов. Каждый инструмент имеет свой входной и выходной формат, и для того чтобы сравнивать на одном наборе тестов необходимо переписать все инструменты к одному виду. Кроме того, часто бывает, что тесты, на которых получали результаты авторы, недоступны для остальных исследователей.
\end{enumerate}
В настоящее время следить за успехами каждого подхода достаточно сложно. Существуют некоторые попытки обобщить и систематизировать методы сравнения инструментов, хотя они не уходят дальше сравнения некоторого узкого множества на наборе тестовых программ. Например, в статье~\cite{Rungta:2009} представляется обзор некоторых существующих методов анализа многопоточных программ.
В статье предлагается набор тестов для оценки качества инструментов анализа многопоточных программ. Набор состоит из тестов Dwyer FSE 2006 и тестов IBM[cite], представляющий собой 45 уникальных программ на Java. Также в статье представлены результаты сравнительного анализа некоторых динамических инструментов %( CalFuzzer, ConTest, CHESS и Java PathFinder).
CHESS используется для проверки C\# программ, остальные - для Java программ. Java PathFinder (JPF) реализует идею уточнения по контрпримерам и динамической редукцией частичного порядка. ConTest и CalFuzzer являются динамическими инструментами. 
CHESS анализирует возможные варианты переключения контекста, ограничивая их число некоторым фиксированным K. Так как он является динамическим инструментом, он требует написание некоторого теста. Важной особенностью является то, что он не создает состояния.
ConTest вносит некоторую случайность в порядок выполнения некоторыхе операцийи синхронизации, выполняющихся в параллельных потоках в процессе выполнения программы.
CallFuzzer состоит из двух частей. RaceFuzzer сначала определяет два потенциальных состояния, в которых возможно состояние гонки. При динамическом запуске этот инструмент пытается привести состояние потоков в выбранныепредполагаемые и проверяет, имело ли место реальное состояние гонки. DeadlockFuzzer сходным образом ищет состояния взаимных блокировок.
В статье представлены результаты запуска на некоторых тестах.

\cite{Wesonga:2011} - инструмент для помощи JPF( визуализация...)
\cite{Dourado:2016} - небольшой набор программ
sv-comp

\section{Методы верификации многопоточных программ с использованием подхода ограниченной проверки моделей}
\label{rw:bmc}

Основная идея методов ограничиваемой проверки моделей заключается в построении конечного пути к ошибке, трансформации этого пути в логическую формулу и проверке этой формулы на выполнимость с помощью специального компонента: решателя (англ. solver). В случае, если формула является выполнимой, это означает, что построенный путь не содержит противоречий и теоретически может быть достижим при реальном выполнении программы.
Основными плюсом данного подхода является строгость доказательства и, как следствие, низкий процент ложных сообщений об ошибках.
Минусом подхода является высокое требование к ресурсам. Кроме того, одним из ограничений подхода является принципиальное отсутствие поддержки операций и объектов, которые могут привести к потенциально бесконечному множеству состояний. К ним относятся, например, циклы, рекурсия, а также операция с динамически выделяемой памятью. 

Для применения таких методов к многопоточным программам необходимо упорядочить последовательность операций во всех потоках, чтобы иметь возможность построить логическую формулу пути. Для этого необходимо определить точки, в которых происходит переключение выполнения операций одного потока на операции другого потока. Это число переключений контекста еще называется чередованием потоков (англ. interleavings). Наблюдение, что ошибки проявляются уже при небольшом числе переключений контекста, позволило ограничить число переключений некоторым небольшим фиксированным K. В условиях ограниченного количества переключений (англ. context bounded switches) применяются различные техники и оптимизации для сокращения пространства состояний. 

Многие методы моделируют взаимодействие между потоками только с помощью операций над глобальными переменными. В этом случае переключение потока имеет смысл рассматривать в случае, если в текущем состоянии происходит доступ к глобальной переменной. Такая идея используется, например, в статье~\cite{Cordeiro:2011}. В ней же описаны еще несколько оптимизаций.

Ленивый подход предполагает, что дерево достижимости обходится в глубину, собираются все полученные ограничения для пути и для каждого узла дерева вызывается обычная процедура для ограниченной проверки модели. Обход дерева останавливается, если была доказано отрицание проверяемого свойства, то есть, найдена ошибка, или если проверены все узлы дерева.

Подход с записью расписания (schedule recording) добавляет к формуле ограничения на планировщик, что позволяет объединить все возможные варианты исполнения программы объединяются в одну формулу и отдать решателю.

Расширяющийся подход (under-approximation and widening approach) основан на том, что сначала строится формула для частного случая взаимодействия процессов, и она проверяется решателем. Если найдена ошибка, значит, более общая модель уже не нужна. Иначе, постепенно отбрасываются ограничения на планировщик, тем самым покрывается все больше вариантов параллельной работы. 

Моделирование примитивов синхронизации происходит с помощью конструкции assume(P), которая рассматривает пути выполнения программы, для которых в данный момент выполнен предикат P. Операция захвата блокировки m представляет собой атомарную последовательность assume(m==0); m=1. Однако для того, чтобы оставалась возможность находить ошибки связанные с взаимной блокировкой (dead locks), для каждого потока вычисляется его состояние: ожидание другого потока, ожидание освобождения блокировки, ожидание сигнала или свободное выполнение. Если нет ни одного потока в свободном состоянии, это означает взаимную блокировку.

Основным недостатком многих методов является слабые экспериментальные данные. В уже упомянутой статье~\cite{Cordeiro:2011} основным результатом, на котором акцентируется внимание является то, что предложенные оптимизации позволяют анализировать программы с 10 переключениями контекста, в то время, как похожие инструменты (в статье упоминаются CHESS[cite] и SATABS[cite]), способны анализировать лишь 5 переключений контекста. При этом тестовый набор составлялся авторами статьи и включал в себя 21 рукописную программу. 

%Статья на месте?
Похожие идеи были представлены в статье ~\cite{Threader:2011}. Более полное содержание метода было описано авторами в статье ~\cite{Gupta:2011:POPL,Gupta:2011}. 
Основная идея метода заключается в поиске некоторого инварианта для программы, из которого следует доказываемое свойство. Этот инвариант может быть выражен с помощью ограниений на глобальные переменные программы, на множество локальных переменных для каждого потока и некоторых ограничений на взаимодействие потоков. В процессе анализа строится абстракция. Если в какой-то момент возникнет состояние, которое не противоречит проверяемому свойству, абстракция уточняется. При этом уточняются как состояния этой абстракции, так и эффекты, то есть, взаимодействие потоков. Стоит отметить, что в данном подходе, также как и в статье~\cite{Cordeiro:2011}, разделяемая память представлена только глобальными переменными, в то время как указатели не рассматриваются вообще. Threader не ограничивает число возможных переключений контекста.

Для оценки результатов использовались примеры, являющиеся упрощенными моделями некоторых реальных программ, таких, как драйвера ОС Windows и Linux. В основном, размер тестов варьировался в районе 100 строк, при этом время работы инструмента на некоторых примерах составляло несколько минут, а на некоторых превышало ограничение в 15 минут. 
В статье~\cite{Threader:svcomp} авторы предоставляют результаты запуска инструмента на некотором общедоступном наборе тестов.
Threader запускался на 32 тестах из категории «Параллельность» и набрал 43 балла из 49 возможных. Правильный вердикт был выдан на 28 тестах.

В статье~\cite{Gupta:2010} авторы предлагают интересное расширение метода CEGAR[cite]. В отличие от классического метода CEGAR, предлагаемый подход сохраняет все ложные контрпримеры, и новая итерация уточнения использует их все. Предикаты, полученные в ходе уточнения не добавляются к старым, а полностью их заменяют, поэтому метод носит название немонотонный. Утверждается, что конкретный набор предикатов не может быть выделен дважды. Таким образом, процесс уточнения абстракции конечен. 

Новый подход к уточнению реализован был реализован в инструменте Threader. Эксперименты на пяти тестах показали, что немонотонный подход работает быстрее и выделяет меньше классов эквивалентности. Однако исследования проводились на пяти небольших примерах, на которых работа инструмента занимает несколько секунд.

В статье ~\cite{Lahiri:2009} авторы представляют инструмент для проверки моделей для применения к низкоуровневому системному коду. Сначала производится трансляция исходной Си программы в программу на языке Boogie~\cite{boogiePL} с помощью инструмента HAVOC~\cite{Chatterjee:2007}.
Это делается для того, чтобы избавиться от таких конструкций, как динамическое выделение памяти, арифметика указателей, преобразование типов. Далее, параллельная программа преобразуется в последовательную, и для нее уже строятся формулы, которые проверяются с помощью SMT решателя.
Для того чтобы повысить масштабируемость метода, применяется слайсинг по полям структур.
Такая идея базируется на предположении, что для проверки конкретного свойства необходимо наблюдение за очень небольшим количеством полей.
Построение множества отслеживаемых полей производится с помощью метода CEGAR. 
Для моделирования переключения контекста для карты памяти глобальных переменных создаются K копий. И переключение контекста моделируется переключением работы с одной картой памяти на другую. Все потоки выполняются один за другим. 
Для верификации программа освобождается от циклов и вызовов функций.
Инструмент запускался на четырех реальных драйверах ОС Windows и в одном даже нашел ошибку. Причем проверяться может некоторое свойство, задаваемое пользователем, например, использование указателя после его освобождения. Было проведено сравнение результатов для случая, когда множество отслеживаемых структур задается вручную, и случаем с уточнением. Уточнение во многих случаях строило большее множество, но на 1-2 поля, то есть отличие составляло несколько процентов, а в некоторых по размеру совпадало с построенным вручную. К сожалению, время работы инструмента приведено только для варианта с уточнением. Оно составляет порядка часа на программу из 600 операторов (locations). 

Продолжение с результатами: ~\cite{Ghafari:2010}

В статье ~\cite{Basler:2009} авторы представляют идею абстракции по программному счетчику. Статья посвящена важной задаче исследования пространства состояний, основанных на BDD-представлении для логических программ. Проблема комбинаторного взрыва локальных состояний решается с помощью метода CEGAR. 
Сначала исходная программа транслируется в логическую, в которой все переменные могут принимать только значения {0,1}. Количество переменных получившейся программы потенциально может быть бесконечно. 
Для снижения затрат ресурсов используется абстракция программного счетчика (counter abstraction). Два глобальных состояния считаются эквивалентными относительно перестановки локальных состояний, количество компонент в локальном состоянии одинаково. Чтобы реализовать эту идею, вводится счетчики для каждого локального состояния, и при переходе из одного состояния в другое увеличивается счетчик полученного и уменьшается для исходного. 
Две основные идеи для снижения затрат ресурсов. 
1) Вместо того, чтобы статически транслировать каждую операцию в обновление программного счетчика, он обновляется динамически, “на лету”. Это приводит к сокращению возможных значений программного счетчика на пути выполнения.
2) Вместо хранения всех программных счетчиков для локальных состояний хранятся только ненулевые счетчики. Этот пункт основан на наблюдении, что для длинных путей, в которых число операций значительно больше числа потоков, большинство программных счетчиков равны нулю.
Для того чтобы еще более повысить скорость работы применяется объединение символических состояний. Оно может произойти, если два состояния отличаются только значением глобальных переменных или локальным состоянием в одном из потоков. 
Для экспериментов было выбрано два набора тестов. Один из них сгенерирован инструментом SatAbs[cite] на основе ядра ОС Linux (http://www.cprover.org/boolean-programs). Второй набор тестов сгенерирован с помощью инструмента SLAM[cite]. N потоков исполняют одну и ту же функцию main. Взаимодействие между потоками происходит только с помощью глобальных переменных. Предложенный алгоритм сравнивался с тем, который реализован в инструменте Murphi[cite]. Предлагаемый подход оказался быстрее в 94\% случаев. Применение объединения состояний при анализе позволяет получить ускорение на 83\%. 

Отдельно следует отметить статьи, посвященные проблеме трансляции параллельной программы в последовательную (англ. sequentilization) с последующей ее верификацией существующими инструментами анализа последовательных программ. Все существующие трансляторы используют следующие ограничения: 
\begin{enumerate}
\item число активных потоков ограничено;
\item взаимодействие между потоками возможно только с помощью глобальных переменных;
\item в каждый момент времени только один поток может быть активен;
\end{enumerate}
Известны несколько методов трансляции ~\cite{Torre:2009, Ghafari:2010,Inverso:2014, Tomasco:2015} авторы предлагают три варианта трансляции: от простого дублирования исполняемого кода до использования сложных и оптимизированных карт памяти, переключение между которыми происходит в случайный момент.
Для верификации новой последовательной программы применяются две основные парагдимы. Одна из них - это логическая проверка моделей, при которой формулы строятся для конечного пути, а проверяется их выполнимость.
Второй вариант - это условная верификация (verification-condition, VC), при которой для построения формул требуется пред- и постусловия и формальные правила преобразования. Эксперименты показали, что эти две парагдимы сильно отличаются, и для них нужны различные способы трансляции. 
Все попытки применения подхода трансяции к последовательной программе в общем случае показывают, что он плохо масштабируется и на реальных программах пока не может быть использован. 

%Однако, этот подход может показывать хорошие результаты, если выбрать специальный класс 
Нужно заметить, что трансляции параллельной программы может производиться не в последовательную, а в некоторую промежуточную модель. Эта модель может быть использована, например, для генерации тестов как это сделано в~\cite{KIM200921}. В ней представлен фраймворк который автоматически транслирует программу на языке C СИ в модель на языке Promela[cite]. Полученная модель верифицируется с помощью инструмента SPIN[cite]. При наличие ошибки полученный контрпример может быть специальным образом преобразован к исполняемому тесту.

В статье~\cite{Atig:2009} авторы рассматривают проблему трансляции программ с динамическим созданием потоков, т.н. асинхроннными вызовами. Число создаваемых потоков может быть потенциально бесконечным, хотя число переключений каждого потока является ограниченным. Эта задача сводится к вопросу о покрытии сетей Петри. Ее решение основано на том, что число потоков, создаваемых из конкретного состояния, включающего локальные и глобальные переменные, конечно. Таким образом на первых L итерациях планирования разрешено создание новых потоков, а в оставшихся K - L итерациях (K - общее возможное число переключений контекста) возможно только переключение, как в классическом подходе. Далее, применяя нетревиальные преобразования, авторы доказывают несколько теорем из которых следует алгоритмическая разрешимость задачи за конечное время.  
Идеи не получили экспериментального подтверждения.

В статье~\cite{Kahlon:2009:SRTI} рассматриваются идеи уменьшения пространства состояний на основе редукции частичных порядков и применении слайсинга. Основной идеей редукции является определение независимых блоков с целью исключения их детального анализа с учетом всех возможных чередований потоков. Зависимость операций определяется по работе с разделяемыми данными, при этом разработан специальный анализ алиасов с использованием обновляющихся последовательностей.
Слайсинг применяется для уменьшения количества рассматриваемых операторов. Некоторые операцторы программы могут быть опущенны из-за ограничений на примитивы синхронизации или из-за недостижимости соответствующих частей кода.

Оценка инструмента проводилась на 9 драйверах Linux с известными гонками. Ожидаемо оказалось, что время работы инструмента является приемлемым только для примеров с небольшим количеством (порядка десятка) разделяемых переменных. Трассы, построенные на основе полученных предупреждений, подавались на вход BMC, который пытался их доказать. В отдельных случаях, время доказательства занимало 10 часов. 

В статье ~\cite{Kahlon:2009} представлен новый подход к редукции частичных порядков, называемый монотонной редукцией. Он основан на новой характеристике частичного порядка, которая определяется через вычисления данной программы в терминах квазимонотонных последовательностей. Этот подход может быть использован и точным, и символическим методами проверки моделей. В статье показано, что ограничения на взаимодействие потоков, построенные на основе квазимонотонных последовательностей гарантируют и корректность, и полноту. 
Отношение независимости определяется, как возможность переставлять операции в двух потоках. Представляеются две стратегии: оптимальная частичная редукция частичных порядков и частичная редукция “дверного глазка” (peephole).
Для оценки результатов использовался модифицированный тест, известный как “обедающие философы”. Сравнение предлагаемого алгоритма производилось со стандартной стратегией BMC.

~\cite{Abdulla:2014:POPL, Abdulla:2014} - одно из развитий

В статье ~\cite{Cohen:2009} авторы подходят к проблеме поиска доказательства для многопоточной программы с другой стороны. 
Для доказательства выполнения некоторого свойства многие инструменты проверки моделей вычисляют достижимые состояния и в каждом из них проверяют выполнение требуемого свойства. Другой подход заключается в локальном доказательстве. Для каждого из потоков записывается свой инвариант в терминах глобальных переменных и доказывается его корректность, а из конъюнкции всех инвариантов следует выполнимость необходимого свойства для целой программы. 
Главная проблема заключается в том, что не всякое доказательство может быть выражено через локальное. И в этом случае поиск локального доказательства будет бесконечным. Основное достижение данной статьи в том, что был предложен конечный метод для поиска локального доказательства. 
Алгоритм поиска доказательства основан на поиске неподвижной точки для предусловий, из которых следует требуемое свойство. Шаг алгоритма, на котором вычисляется следующее приближение для вектора локальных предусловий называется фазой уточнения. Если в процессе уточнения получена неподвижная точка, то есть вектор из предусловий равен тому, который был на предыдущем шаге, поиск доказательства заканчивается. Далее доказывается, что такой алгоритм корректен и конечен. 
Во многих тестах (со слов авторов) их подход показал хорошие результаты. 

Для помощи инструменту верификации можно предоставлять некоторые подсказки - аннотации. Вовлечение человека в процесс верификации несомненно повышает качество и скорость, однако требует определенных затрат времени на написание таких аннотаций. 
В статье ~\cite{VCC:2009} представлен верифицирующий Си компилятор (VCC), который интегрирован в Microsoft Visual Studio. Это полностью автоматическая система, которая может верифицировать аннотированные программы. Аннотации представляют собой инварианты, пред- и постусловия. Из аннотаций генерируются формулы логики первого порядка, которые разрешаются с помощью решателя.

Похожая идея демонстрируется в статье ~\cite{Burnim:2009}, в которой представлен фреймворк для аннотации Java программ. Аннотации представляют пред- и постусловия для некоторых блоков кода, которые проверяются по ходу выполнения программы. 
Для оценки работы инструмента использовалось два набора тестов: Java Grande Forum (JGF) и Parallel Java (PJ) Library, в сумме 13 тестов 1000-4000 строк кода. В среднем потребовалось около 10 строк аннотаций, чтобы найти те же гонки, что и CalFuzzer. 

Статья ~\cite{Ganty:2009:POPL} посвящена проблеме проверки живучести асинхронных программ. Задача ставится: проверить свойства завершаемости и неголодания. Завершаемость означает, что из каждой процедуры есть возврат и нет бесконечного запуска процедур. Второе свойство - неголодания (non-starvation) означает, что из каждой процедуры есть возврат, а при бесконечном выполнении все процедуры обрабатываются, то есть нет такой, выполнение которой постоянно откладывается. 
Доказательство этих двух свойств осложняется тем, что программа потенциально может содержать неограниченное количество вызовов функций, например, из-за рекурсии.
По асинхронной программе строится конечный автомат. Проверка завершаемости программы переформулируется в проверку некоторого свойства этого автомата. Далее показывается, что для любого автомата, можно построить автомат, не содержащий рекурсии, множество достижимых состояний которого совпадет с исходным. По такому автомату строится сеть Петри, на которой уже показывается выполнимость требуемого свойства завершаемости. Для сети Петри это означает, что не существует графа покрытия, как конечного автомата. Проверка этого условия сводится к проверки разрешимости формулы в арифметике Пресбургера. Так как каждый шаг алгоритмически разрешим, в итоге проверка свойства живучести программы алгоритмически разрешима. 
Статья крайне теоретизирована, и нет никаких экспериментов.

Очень интересная идея была описана в статье ~\cite{Leino:2009}. В ней представлен подход к верификации многопоточных программ, основанный на понятии разрешения. Так, поток имеет право на доступ к некоторой ячейке памяти, если у него есть на это разрешение, которое представляет вероятность от 0 до 100\% включительно. Значение 100\% означает эксклюзивный доступ на запись, любое число от 0 до 100 - доступ на чтение. Для каждой функции записывается предусловие, в котором указывается, какое значение для разрешения требуется для ее выполнения. Отдельно нужно заметить, что рассматриваются объектно-ориентированные программы, в которых синхронизация между потоков осуществляется с помощью мониторов. Мониторы представляют собой блокировки, которые используются для защиты от одновременного доступа некоторые области памяти. Во время создания нового объекта или захвата монитора для него разрешение устанавливается на 100\%. При доступе к объекту строится формула из ограничений и подается на вход решателю.
Никаких экспериментов не было проведено.

Слабые модели памяти! Например ~\cite{Zhang:2015:PLDI, Zhang:2015}

%\newpage
%============================================================================================================================

\section{Методы статического анализа многопоточных программ}
\label{rw:static}
Статический анализ традиционно применяется на больших программных системах, на которых нельзя провести формальную проверку моделей. Он отличается большим набором проверенных ситуаций, чем динамический анализ, но не может претендовать на формальное доказательство отсутствия ошибок.

В статье ~\cite{Yahav:2008} описывается фреймворк для доказательства корректности параллельных программ, которые динамически выделяют память. Он позволяет встраивать в себя различные алгоритмы доказательства для различных свойств безопасности. Семантика Java-программы описывается с помощью мета-языка, основанного на логике первого порядка. Далее, вычисляется аппроксимация множества достижимых состояний (обычно бесконечного). С помощью теории абстрактной интерпретации формулируются абстрактные состояния, которые представляют некоторое множество конкретных достижимых состояний. Для каждого оператора программы вычисляется эффект, или действие, которое представляет собой формулу логики первого порядка. Это является важным отличием от других инструментов проверки моделей, в которых используется логика высказываний.
Действие может изменить абстрактное состояние. При получении нового абстрактного состояния фреймворк проверяет, что оно удовлетворяет сформулированным свойствам безопасности. Таким образом, может быть получено ложное предупреждение о нарушении свойства, но оно никогда не будет пропущено.
Во фреймворке могут быть заданы следующие параметры:
1) что является конкретным состоянием;
2) как конкретные состояния абстрагируются;
3) семантика операторов, т.е. как операторы меняют абстрактное состояние;
4) определение свойств, которые необходимо проверять.
Можно выделить следующие основные особенности фреймворка.
1) Не требуется создание графа абстрактных состояний сразу для всей программы.
2) Абстрактное состояние представляют собой глобальное состояние программы, а не только взаимосвязь между выделенными областями памяти. Это позволяет комбинировать информацию о планировании потоков с информацией о динамически выделенной памяти.
3) Графы потока управления потоков представляются не раздельно, а собираются в одно глобальное состояние, что после абстрагирования потенциально позволяет рассматривать неограниченное количество потоков.
ESP[cite] и SLAM[cite] перед непосредственно верификацией программы проводят анализ указателей, результаты которого используются в дальнейшем. Такое разделение приводит к неточностям анализа. Описываемый фреймворк производит верификацию и анализ указателей одновременно, что позволяет повысить точность. Однако, было бы неверно сравнивать только точность без масштабируемости. С точки зрения практического использования и двухфазный подход, и интегрированный ограничены. В первом случае потеря точности не позволяет верифицировать многие свойства корректно, а второй подход не позволяет верифицировать реальные программы из-за большого размера. В будущем планируется применить некоторые техники для увеличения масштабируемости, такие как динамическая частичная редукция (dinamic partitial-order reduction) и стадийность (staging)[cite]. 
Фреймворк оценивался на восьми тестах. При наличиие ошибки в программе достаточно бывает нескольких десятков состояний. А для доказательства ее отсутствия приходится рассмотреть несколько тысяч. Самый большой тест занял около двух часов.

Статья ~\cite{Pratikakis:2011} представляет инструмент Locksmith для статического поиска гонок.
Locksmith реализован на основе библиотеки CIL[cite], которая используется для разбора исходного кода.
На первой фазе анализа Locksmith обходит граф потока управления и создает две ключевые абстракции: ограничения потока меток (label flow constraints), чтобы смоделировать поток данных в программе, и ограничения потока управления (control flow constraints), чтобы смоделировать последовательность действий и связать ее с первым типом ограничений. Анализ потока меток чувствителен к полям структур (field-sensitive), это значит, что каждое поле моделируется независимо от других. Возникают различные проблемы с моделированием указателей типа void, и в статье было рассмотрено несколько вариантов их решения. Чтобы достигнуть контекстной чувствительности, информация о вызове функции добавляется в граф потока меток. Ограничения потока управления представляют собой граф потока управления каждого потока.
Следующая стадия называется анализ разделяемости данных, на которой определяются те области памяти, которые доступны из нескольких потоков. Для каждой операции вычисляется эффект - множество областей памяти, к которым происходит доступ. Будущий эффект (future effect) потока — это множество всех эффектов для каждой из операций. Пересечение будущих эффектов для потоков и дает множество разделяемых областей памяти.
Анализ захваченных блокировок идет параллельно предыдущему анализу. После каждой операции вычисляется множество захваченных блокировок.
Следующий шаг — вывод корреляции (correlation inference). В этот момент пересекаются множества захваченных блокировок для каждого доступа к разделяемой переменной. Это центральный момент анализа, после которого возможен вывод предупреждений или применение дополнительных эвристик.
Locksmith запускался на шести приложениях с использованием POSIX потоков и на девяти драйверах ОС Linux. Для POSIX приложений время анализа мало меняется и составляет около 0.5 с на 1000 строк кода. Для драйверов это время в среднем составляет 1с на 1000 строк кода, но в отдельных случаях возрастает до 60 с на 1000 строк кода. Для POSIX приложений число истинных ошибок составляет 29\% от числа ложных срабатываний, для драйверов — 9\%. Большинство ложных срабатываний связано с неточноностью анализа разделяемых данных.

Статья ~\cite{Kahlon:2009:SDR} посвящена проблеме построения графа потока управления для многопоточной программы, если в ней имеются вызовы по функциональным указателям, а также проблеме анализа алиасов в этом случае. Программа должна быть написана в соответствии с моделью fork-join[cite]. Для нее строится параллельный граф потока управления, который представляет собой обычный ГПУ для каждого из создаваемых потоков. 
Далее рассматривается идея бутстрепинга[cite] для быстрого определения множества алиасов. Она основана на разбиении Стинсгаарда[cite] применительно к алиасам. Так, указатели могут быть алиасами указателей только из своего подмножества. Идея заключается в том, чтобы не следить за присваиванием всех возможных пар указателей, а только за теми, которые относятся к своему классу эквивалентности. Вторым важным понятием являются обновляющие последовательности - это последовательность присваиваний, которая обновляет указатель. Соответственно, p и q могут быть алиасами, только если существует обновляющая последовательность от p к q. Так как разбиение Стинсгаарда обычно невелико, то строить обновляющие последовательности, чтобы доказать корректность алиасов, приходится нечасто. 
Отдельно рассматривается вопрос о рекурсии. Граф потока управления раскручивается до тех пор, пока не будет найдена неподвижная точка в терминах разбиения Стинсгаарда. Полученный граф состояний обходится и анализируется на предмет наличия состояний гонки с помощью стандартного алгоритма Lockset. Разделяемые переменные определяются, как алиасы к глобальным переменным. Что будет со списками пока непонятно. Рассматриваются три модели потоков. Первая - самая простая, в которой считается, что каждая функция может выполняться параллельно с каждой. Вторая модель - fork-join, в которой параллельность начинается с ключевого слова fork и заканчивается после join. Третья модель отличается от предыдущей отсутствием точек join и ограничением на количество задач на одном потоке. Это приводит к тому, что некоторые ситуации гонки оказываются невозможны. Инструмент проверялся на нескольких драйверах OC Linux,  алгоритме параллельного сжатия bzip2smp, параллельном MPEG декодере и некотором параллельном продукте. На небольших программах инструмент работал несколько секунд. Порядок количества предупреждений совпадал с порядком числа разделяемых переменных. Отдельный запуск на большой системе занял 22 минуты. Однако, разделяемых переменных было всего 4, поэтому количество предупреждений оказалось невелико. 

Проблема анализа алиасов по-своему решается в статье ~\cite{Seidl:2009}.
Цель анализа регионов - показать, что выделенная на куче память корректно разделена на непересекающиеся блоки. Первый подход основан на сложном анализе размера структур данных. Этот подход очень плохо масштабируется на большие программы. Другой подход работает с динамически выделенными объектами, как с блоками памяти, связанными с абстрактными состояниями. В этом случае возникают проблемы с анализом областей памяти, выделенных в одной точке программы. В статье описан анализ регионов достаточно быстрый и точный для программ, работающих с непересекающимися областями памяти. Данный анализ может быть расширен до метода поиска гонок с использованием стандартного алгоритма Lockset. 
Две глобальных переменных считаются эквивалентны, если доступ к некоторой ячеки памяти можно получить и через первую переменную, и через вторую. Анализ хранит информацию об эквивалентности переменных для каждой точки программы. Кроме того, хранится для каждого локального указателя хранится множество областей памяти, куда он может указывать, т.н. may-алиасы. Для поиска гонок отдельно собираются must-алиасы для указателей на блокировки. 
Данный анализ может быть расширен для обработки массивов. Так, каждый элемент массива считается отдельной переменной. Если индекс массива участвует в операциях сложения и вычитания, анализ будет выполнен корректно. При присваивании в него результата другой операции, соответствующая информация о всех элементах массива удаляется, так как неясно, в какой именно элемент происходит доступ. 
При применении инструмента к модулям ОС Linux авторы столкнулись с проблемами обработки структур, содержащих массивы, арифметикой указателей, преобразованием типов (кастированием). Были попытки расширить возможности анализа, например, предположением, что указатель может указывать не только на начало блока памяти. 
Инструмент запускался на 9 драйверах. Время работы составляло в среднем 1-2 секунды. Число разделяемых переменных оказалось невелико, не больше 5.

Зачастую инструменты статического анализа нацеливаются на эффективный поиск некоторого класса ошибок. Например, в статье ~\cite{Naik:2009} представлен алгоритм поиска состояний взаимной блокировки для Java программ. Инструмент производит k-объектный, контекстно-чувствительный анализ исходного кода, строит граф вызовов и граф указателей (points-to). Выделяются все возможные места, в которых возможна блокировка, то есть состояния, в которых захвачены некоторые блокировки и ожидается их освобождение. После чего применяется ряд фильтров:
1) Состояния должны быть достижимы.
2) Должно быть показано, что блокировки действительно парные. То есть, либо их точное равенство, либо возможность быть алиасами.
3) Должно быть показано, что не возможно освобождение блокировки из другого потока. 
4) Возможность параллельной блокировки, то есть возможность оказаться двум потокам одновременно в соответствующих состояниях.
5) Блокировки должны быть разными, то есть встречается перезахват одной и той же блокировки. Это требует точного анализа алиасов (must-aliases).
6) Отсутствие общей блокировки. Для того чтобы предотвратить взаимную блокировку, возможен захват некоторой общей.
Инструмент проверялся на наборе тестов, которые включали в среднем 100 000 операторов (locations), содержали несколько сотен классов. Время анализа составляло около 10 минут. Важно замететить, что алгоритм является неточным. Первое ограничение в том, что поиск взаимных блокировок ведется между парами потоков. Большее количество не учитывается. Второе важное ограничение - это учет синхронизации только на основе блокировок.

Очень интересна работа ~\cite{Xiong:2010}, которая посвящена поиску неявных типов синхронизаций.
В статье проведен анализ нескольких больших программных продуктов на предмет наличия в них неявнных или специальных (ad hoc) видов синхронизации, например, таких как ожидание в цикле, пока некоторая переменная не примет определенное значение. Важно заметить, что если в программе определяется некоторая функция, которая используется для синхронизации, она не считается неявной.
В процессе исследования были получены следующие результаты.
1) Каждая изученная параллельная программа использует неявную синхронизацию. 
Процент очень сильно варьируется от 6-83%.
2) В основном, все неявные типы синхронизации представляют собой бесконечные циклы, выход из которых возможен при специальном условии. Но несмотря на это, такие неявные синхронизации тяжело определять.
3) В 22-67\% случаях неявный способ синхронизации приводил к ошибкам. Обычно это выражалось во взаимной блокировке или зависанию системы. 
4) Из-за того, что многие инструменты не могут определить неявную синхронизацию, пропускается большое число ошибок. 
Для помощи разработчикам был создан инструмент, который аннотирует синхронизационные циклы. Его алгоритм заключается в следующем. Сначала он выделяет все циклы. Далее, изучает условия, при которых происходит выход из цикла и определяет те, в которых переменные могут быть доступны другому потоку. В большинстве случаев, условие при синхронизации является инвариантом цикла с тем, чтобы переменная была обновлена из другого потока. После таких проверок определяется множество циклов, которые могут быть использованы для синхронизации. Далее, выполняется поиск парной операции, которая обновляет переменную, участвующую в условии цикла. Инструмент сделан на основе LLVM  компилятора и переиспользует его промежуточное представление. Были попытки учета значения, которое записывается в разделяемую переменную, с тем, чтобы, используя SAT решатель, формально показать, что цикл является неявной синхронизацией, однако этот подход оказался слишком тяжеловесным. Обычно в такую переменную явно присваивается число, при том один раз, проверяется также обычно на равенство конкретному значению, поэтому можно использовать более простые техники, чем решатели. В инструменте используется распространение ограничений. 
В результате каждый найденный синхронизационный цикл аннотируется. Такой результат может быть использован в двух аспектах. Во-первых, разработчики могут вручную просмотреть каждый цикл и понять, является ли он ошибкой или нет. На проведенных тестах инструмент верно нашел 96\% неявных способов синхронизации. При этом число ложных сообщений об ошибках было всего 6\%. Во-вторых, другие инструменты поиска гонок могут использовать данные аннотации для более точного анализа. Так, эксперименты с Valgrind показали, что число ложных предупреждений сокращается на 43-86\%. 

%\newpage
%============================================================================================================================

\section{Методы динамического анализ многопоточных программ}
\label{rw:dynamic}

Динамический анализ активно применяется для поиска частовозникающих ошибок, его основное достоинство заключается в том, что его процент ложных срабатываний значительно меньше, чем у статического. Динамический анализ традиционно борется за снижение замедления выполнения программы и за сокращение требуемой для анализа памяти. 
Рассмотрим основные инструменты динамического анализа, предназначенные для поиска состояний гонок. Все они используют идею векторных часов Лампорта и некоторые оптимизации для того, чтобы сократить накладные расходы. В основном, она заключается в сэмплинге (sampling), то есть в уменьшении объема памяти, за которой производится слежение. С помощью векторных часов строится отношения happens-before для всех операций. Если для двух доступов к памяти невозможно указать порядок, то есть, построить отношение happens-before, выдается предупреждение о возможном состоянии гонки. 
В статье ~\cite{Flanagan:2009:PLDI, Flanagan:2009} описывается инструмент динамического поиска гонок в Java программах, который использует следующую оптимизацию. Так как запись всех действий в программе занимает слишком много времени, то сохраняются только самые последние доступы к переменной. Менее 1\% случаев гонок требуют полного сохранения векторных часов, в остальных случаях достаточен более легковесный подход. Используется понятие эпоха - это идентификатор векторных часов и номер потока. Инструмент позволяет адаптивно выбирать, сохранять ли конкретное значение векторных часов для некоторой переменной или только эпоху. Такой подход позволяет уменьшить накладные расходы, не потеряв точности.  
Состояние потока включает в себя векторные часы, значение векторных часов для освобождаения каждой блокировки, эпоху или вектор часов для последнего чтения каждой переменной и эпоху последней записи в каждую переменную. 
Инструмент сравнивался со множеством других аналогичных детекторов на 16 тестах. Все предупреждения были выданы для инстинных ошибок. Требуемое для анализа время, в среднем, в 4-5 раз больше, чем для работы исходной программы. Другие инструменты, основанные на том же методе векторных часов в отдельных случаях увеличить время работы в 300 раз. Объем требуемой памяти возрастает на 20-30\%.

В статье ~\cite{Sadowski:2009} представлен инструмент для динамической проверки в Java программах двух свойств:
1) Отсутствие конфликтов между потоками внутри одной транзакции.
2) Потоки внутри транзакции не должны влиять на потоки вне ее. 
Для проверки первого условия используется алгоритм векторных часов, который строит отношение happens-before внутри транзакции. Для проверки второго условия тот же самый граф happens-before строится для транзакций в целом. 
Конфликтом называется ситуация, в которой происходит обращение к одним и тем же данным из разных потоков или захват/освобождение одной и той же блокировки. Кроме того, к конфликтам относятся операции в потоке до его создания (fork) или после завершения (join). Транзакцией является некоторая последовательность операций. 
Инструмент принимает на вход Java байткод. Он был проверен на восьми тестах JavaGrande, каждый тест был размером около 1000 строк кода. Замедление времени работы составило около 10 раз. 

В статье ~\cite{Marino:2009:PLDI, Marino:2009} представлена оптимизация, основанная на гипотезе “холодных регионов”: предполагается, что состояния гонки, скорее всего, проявятся в редко исполняемых участках кода, так как на часто исполняемых они уже исправлены. При таком предположении можно уменьшить количество памяти, за которой происходит слежение. Таким образом, за горячими участками слежение почти не ведется, а доступы к памяти из холодных участков отслеживаются полностью. При этом горячие участки кода вычисляются отдельно для каждого потока.

В среднем, накладные расходы составляют 28\% времени работы, хотя в некоторых случаях достигают 100\%. Это в 25 раз меньше, чем если бы обрабатывались все обращения к памяти.

[27] Qi Y., Das R., Luo Z., Trotter M. MulticoreSDK: a practical and efficient data race detector for real-world applications. Proceedings Software Testing, Verification and Validation (ICST), IEEE, 21-25 March 2011. P. 309–318.

Статья~\cite{Bond:2010:PLDI,Bond:2010} представляет еще один инструмент - PACER, который использует следующую оптимизацию: доступы к памяти учитываются только в период выборки (sampling period).
Инструмент Pacer дает гарантии того, что существующая гонка будет найдена с вероятностью равной уровню выборки (sampling rate). Pacer случайно включает и выключает слежение за динамическими операциями (sampling period). Во время слежения он автоматически подбирает уровень слежения (sampling rate) такой, чтобы вероятная ошибка нашлась с заданной вероятностью. Во время периода слежения, Pacer обрабатывает все операции, связанные с синхронизацией, и все доступы к переменным. В оставшееся время, инструмент следит только за теми переменными, которые он выбрал.
В итоге для уровня выборки от 1-3\% накладные расходы составляют 52-83\%.
Однако метод выбора объектов слежения имеет два важным недостатка:
1) Можно пропустить важные happens-before дуги, которые приведут к ложному предупреждению.
2) При уровне выборки r число найденных состояний гонок будет лишь $r^2$. 
LiteRace инструментирует все операции синхронизации, чтобы решить первую проблему. Для решения второй он ищет состояния гонок только в холодных участках кода. Еще важное отличие LiteRace в том, что он детерминирован, а Pacer намеренно использует случайные значения, чтобы найти состояния гонки, которые были пропущены в предыдущих запусках.
Pacer случайно включает и выключает слежение за динамическими операциями (sampling period). Во время слежения он автоматически подбирает уровень слежения (sampling rate) такой, чтобы вероятная ошибка нашлась с заданной вероятностью. Во время периода слежения, Pacer обрабатывает все операции, связанные с синхронизацией, и все доступы к переменным. В оставшееся время, инструмент следит только за теми переменными, которые он выбрал.
Для оценки использовались 4 набора тестов, на каждом из которых было сделано 50 запусков. Ошибки, проявившиеся хотя бы на половине из запусков, составляют около трети от числа тех, которые проявились хотя бы на одном.

Статья ~\cite{Serebryany:2011} представляет улучшение метода, реализованного в инструменте ThreadSanitizer-Valgrind[cite], представленного ранее. Основная часть логики метода осталась той же самой, однако в следствие использования компилятора LLVM удалось повысить скорость работы, а также портируемость, с которой были большие проблемы. 
TSan-LLVM использует инструментацию во время выполнения программы, что приводит к замедлению ее работы в 2-3 раза. Сам алгоритм анализа может быть представлен в виде конечного автомата, который обрабатывает произошедшие в программе события, такие как чтение, запись, захват блокировки и др. Для определения состояния гонки используется и Lockset алгоритм, и Happens-Before, что позволяет повысить точность. 
Инструментация производится на уровне промежуточного представления LLVM. Она необходима для того, чтобы собирать информацию о стеке вызовов функций, а также о доступах к памяти. 
Для того, чтобы уменьшить расходы на анализ, применяется выборочное слежение за доступами к памяти (sampling). Для этого была принята гипотеза о том, что состояния гонки, скорее, встретится в “холодных” функциях, потому что в часто используемых областях состояния гонки либо уже исправлены, либо неопасны. В отличие от LiteRace, который применяет ту же идею, TSan всегда выполняет инструментированный код, но если для данного потока счетчик выполнений данной операции выше уровеня упрощения (sampling rate), то информация о доступе к памяти игнорируется. Второе важное отличие заключается в том, что LiteRace считает холодными участками кода целые функции, TSan оперирует на уровне базовых блоков, что уточняет анализ.
Основной недостаток инструментации во время выполнения - это то, что могут быть потеряны ошибки, находящиеся в коде, которые не компилируется: системные библиотеки или JIT код. 
Сравнение подхода показало, что, в среднем, применение инструментации позволяет ускорить работу в 2-3 раза по сравнению с оригинальным TSan-Valgrind и в 10 раз по сравнению с другими инструментами, такими, как Valgrind. Однако, не сравнивалось число найденных ошибок. 

Также, как и статические методы, динамические инструменты могут быть нацелены на конкретные классы ошибок. В статье~\cite{Park:2009:ASPLOS,Park:2009:SIGARCH,Park:2009} описывается подход к динамическому поиску конкретного класса ошибок в многопоточных программах - нарушениям атомарности операций. Чтобы уменьшить объем анализируемых данных, все возможное множество вариантов переключения контекста ограничивается теми, которые соответствуют несериализуемым взаимодействиям (unserializable interleavings). Для таких взаимодействий не существует никакого последовательного эквивалента выполнения участвующих операций. Из этого множества нужно исключить невыполнимые варианты взаимодействия, например, защищенные одной и той же блокировкой. Инструмент умеет определять часто возникающие ситуации и фокусируется на редких. Анализ делится на несколько стадий. Сначала запускаются несколько тестов для профилирования, затем определяются все возможные нарушения атомарности, после чего выделяются достижимые. Далее, полученное множество упорядочивается по частоте возникновения.
Инструмент запускался на таких промышленных программных системах, как MySQL, Apache, Mozilla и др. Затраченное время на анализ оказалось в 10-1000 раз меньше, чем у других подходов. 

В статье ~\cite{DataCollider} представлен оригинальный способ поиска гонок в ядре ОС.
Одна из проблем поиска гонок в ядре операцонной системы заключаются в том, что ядро ОС оперирует более низким уровнем абстракции, чем пользовательские приложения. Вторая важная особенность - это проблема поиска состояния гонки в случае, когда обращение к данным происходит от аппаратуры. И, наконец, многие динамические инструменты значительно замедляют работу программы. К К тому же они используют инструментацию, которую довольно сложно применить к ядру ОС. 
DataCollider расставляет несколько точек прерывания на случайные доступы к памяти. Когда программа доходит до них, выполнение останавливается, сохраняется значение той ячейки памяти, куда происходит обращение, и спустя какое-то время проверяет, что значение не изменилось. В ином случае фиксируется состояние гонки. Для того чтобы получить информацию о потоке, из которого произошел второй доступ к памяти, используются аппаратные прерывания, которые ставятся на доступ к конкретной области памяти. Значительное преимущество инструмента состоит в том, что нет необходимости разбираться в сложных примитивах синхронизации ядра.
Не все состояния гонки ведут к ошибкам. Так, эксперименты с DataCollider показали, что только 10\% предупреждений соответствует истинным ошибкам. Чтобы уменьшить число ложных предупреждений используется некоторая обработка информации после анализа.
Для определения точек расстановки прерываний DataCollider дезассемблирует исполняемый файл и получает множество всех областей памяти. Далее, используя простые алгоритмы статического анализа, он отсеивает те локальные области памяти, доступ к которым никак не может привести к состоянию гонки. Из оставшихся выбираются те, за которыми будет следить инструмент, и на них расставляются точки прерываний. В случае, если во время работы инструмента была найдена ошибка, то соответствующая ей точка прерывания удаляется и выбирается новый доступ к памяти. Во время работы DataCollider следит за количеством прохождений выбранных точек прерываний. Если оно больше или меньше, чем некоторое целевое значение, точка останова может быть удалена, и выбрана новая.
DataCollider был применен к нескольким драйверам ОС Windows. Было найдено 38 состояний гонки. При этом замедление работы было всего 10-15\% процентов. 

В статье ~\cite{Fonseca:2010} представлен анализ ошибок, исправленных в сервере MySQL в процессе разработки от версии 3.x до версии 6.х. Все исправления (12500 коммита) были отфильтрованы по ключевым словам, относящимся к параллельному выполнению (concurrent, atomic, lock, synchronization и др). Из этого множества (583 ошибки) были исключены те ошибки, описание которых было недостаточно ясное (347 ошибок). После чего были выбраны некоторые из этих ошибок, которых оказалось 80, и проанализированы вручную.  
Результаты показали, что ошибки, связанные параллельным выполнением становятся все более и более распространенными. Состояние взаимной блокировки вызывали 40\% ошибок. 28\% всех ошибок приводили к падению системы, а 15\% - к предоставлению неверных данных пользователю. 15\% всех багов приводили к ошибки не сразу, т.н. “скрытые” баги, причем 92\% из них впоследствии проявляют себя тем, что выдают пользователю невереные данные - это семантические баги. Эта категория была проанализирована более детально. Больше половины из семантических багов (58\%) нарушала порядок выполняемых транзакций. 25\% багов нарушали свойство изолированности транзакций. Ключевые структуры данных, которые повреждались при скрытых багах следующие: файлы с данными, с индексами и с определениями, кэши запросов и ключей, лог. 
На нахождение ошибок в среднем уходило 3-4 месяца после ее внесения. Для поиска ошибок, вызывающих повисание системы требовалось до 7 меяцев.
Далее, в статье ~\cite{Fonseca:2011} авторы рассказывают о своем опыте поиска гонок в MySQL сервере.
Сначала вводится понятие истории - конечной последовательности событий, которые могут быть либо вызовом операции, либо ее ответом. История индуцирует частичный порядок на множестве событий: операция о1 происходит раньше о2, если ответ операции о1 происходит раньше, чем начало выполнения о2. Далее, определяется линеаризуемость. История событий в параллельной системе линеаризуема, если существует история событий последовательной системы, для которой порядок событий не нарушается. Это означает, что несмотря на внутренний параллелизм, сервер ведет себя так, как если бы все запросы выполнялись последовательно. 
Метод тестирования основан на том, что каждое параллельное выполнение сравнивается со всеми возможными его линеаризациями. Если ни одна из них не соответствует реальной трассе, фиксируется ошибка. 
Для того, чтобы найти скрытые ошибки, которые повреждают структуру данных, а не логику выполнения, необходимо применить описанный метод не в конце выполнения, а для каждого внутреннего состояния программы. Отдельный вопрос, как понять и описать это состояние. Это задача тестировщика, либо разработчика, который должен явно указать, что считать состоянием. Для этого они должны реализовать функцию суммирования состояния (state summary function), которая предоставляет ту информацию, которая в дальнейшем считается описанием состояния программы. Была реализована некоторая библиотека, которая позволяет упростить написание такой функции. В процессе выпуска новых версий программы ее логика не меняется, поэтому уже функции суммирования нужно написать единственный раз.
Традиционный подход к динамическому анализу многопоточных программ основан на стрессовом тестировании и генерации шума. Однако он имеет три ограничения. Во-первых, этот подход не систематичен, то есть не позволяет избежать анализа лишних или похожих событий. Во-вторых, в таком подходе невозможно выделить приоритетные события, которые, скорее всего, приведут к ошибке. И, наконец, даже если ошибка обнаружена, ее крайне сложно воспроизвести.
Инструмент PIKE пытается обойти эти ограничения с помощью алгоритма случайного планирования. При старте программы планировщик выбирает случайный приоритет для каждого потока. В каждый момент времени активен поток с наибольшим приоритетом. Приоритет случайным образом меняется в некоторых случайных точках программы. 
Для оценки результатов анализировался MySQL сервер, развернутый на кластере из 15 машин. Было проведено 1550 тестов, на каждом из которых было исследовано до 400 различных переключений контекста, используя описанный алгоритм планирования. Это заняло более месяца, однако имеются варианты ускорения тестирования, такие как метод мгновенного снимка (snapshotting), который позволяет сэкономить время на инициализацию сервера. Были найдены две ошибки, которые могли вызывать падение сервера, и 10 ошибок, которые приводили к некорректной работе сервера.
Примерно треть всех тестов привела к ложным предупреждениям об ошибках, однако, оказалось, что большинство из них связано с работой с различными кэшами. При параллельном доступе к кэшу по одному ключу, программа считает всю запись недействительной. Но это не приводит к ошибке, лишь к увеличению времени работы. Однако, инструмент выдает предупреждение об ошибке. Чтобы это обойти, было написано несколько фильтров к различным кэшам, которые проверяют, что в при линеаризованном запросе состояние (в данном случае, кэш) включает в себя состояние параллельного запроса, и в этом случае не выдается предупреждение.

Статья ~\cite{Vafeiadis:2010} посвящена понятию линеаризуемости.
Линеаризуемость - это свойство корректности параллельных реализаций абстрактных структур данных (стек, очередь, и др.). Оно требует, чтобы каждая операция была атомарна и удовлетворяла заданной функциональной спецификации. Один из способов доказать линеаризуемость - это определить точки линеаризации программы, в которых сосредаточена основная функциональность.
Предполагается, что программа состоит из некоторой части с инициализацией, после которой идет параллельное выполнения некоторого ограниченного, но заранее неизвестного числа потоков. Состояние программы включает в себя глобальные переменные и локальные переременные для каждого потока вместе со счетчиком команд.
В статье было выдвинуто наблюдение, что операции имеют сложные условные точки линеаризации, если их выполнение не меняет состояния программы. В таком случае выполнение называется свободным (pure), а иначе - эффективным. Для доказательства линеаризации для каждого метода вводится массив can\_return, который содержит true, если для конкретного потока и выполняемого при конкретном возвращаемом значении этого метода была достигнута точка линеаризации, и глобальное состояние этой программы не изменилось.
Для каждой операции (метода) в проверяемом классе пишется спецификация в терминах абстрактных состояний. В каждой спецификации выделяются пути ее выполнения. Для каждого пути строятся проверки чистой линеаризации (pure linearizability checkers). Они представляют собой присваивание в уже упомянутый массив can\_return true в случае, если на рассматриваемом пути не происходит изменения глобальной переменной. Если на пути происходит запись в глобальную переменную, операция считается эффективной, и точка линеаризации соответствует присваиванию в глобальную переменную. В соответствии со спецификацией инструментируется исходный код метода. Так, во время присваивания в глобальную переменную проверяется, что в метапеременной, хранящий результат вызова этого метода, еще ничего не записано. А в конце выполнения проверяется, что либо возвращаемый результат равен тому, что хранит эта метапеременная, то есть достигнута эффективная точка линеаризации, либо в массиве can\_return на соответствующем месте стоит true, то есть достигнута чистая точка линеаризации. Если проверка проходит неуспешна, фиксируется ошибка.
Инструмент был проверен на восьми тестах, в среднем каждый занимал 100 строк кода. 

Сошлёмся на приложения: Приложение \ref{AppendixA}, Приложение \ref{AppendixB2}.

Сошлёмся на формулу: формула \eqref{eq:equation1}.

Сошлёмся на изображение: рисунок \ref{img:knuth}.

%\newpage
%============================================================================================================================

\section{Формулы} \label{sect1_3}

Благодаря пакету \textit{icomma}, \LaTeX~одинаково хорошо воспринимает в качестве десятичного разделителя и запятую ($3,1415$), и точку ($3.1415$).

\subsection{Ненумерованные одиночные формулы} \label{subsect1_3_1}


В формулах можно использовать греческие буквы:
\[
\alpha\beta\gamma\delta\epsilon\varepsilon\zeta\eta\theta\vartheta\iota\kappa\lambda\\mu\nu\xi\pi\varpi\rho\varrho\sigma\varsigma\tau\upsilon\phi\varphi\chi\psi\omega\Gamma\Delta\Theta\Lambda\Xi\Pi\Sigma\Upsilon\Phi\Psi\Omega
\]

%\newpage
%============================================================================================================================

\subsection{Ненумерованные многострочные формулы} \label{subsect1_3_2}

Вот так можно написать две формулы, не нумеруя их, чтобы знаки равно были строго друг под другом:
\begin{align}
  f_W & =  \min \left( 1, \max \left( 0, \frac{W_{soil} / W_{max}}{W_{crit}} \right)  \right), \nonumber \\
  f_T & =  \min \left( 1, \max \left( 0, \frac{T_s / T_{melt}}{T_{crit}} \right)  \right), \nonumber
\end{align}

Выровнять систему ещё и по переменной $ x $ можно, используя окружение \verb|alignedat| из пакета \verb|amsmath|. Вот так: 
\[
    |x| = \left\{
    \begin{alignedat}{2}
        &&x, \quad &\text{eсли } x\geqslant 0 \\
        &-&x, \quad & \text{eсли } x<0
    \end{alignedat}
    \right.
\]
Здесь первый амперсанд (в исходном \LaTeX\ описании формулы) означает выравнивание по~левому краю, второй "--- по~$ x $, а~третий "--- по~слову <<если>>. Команда \verb|\quad| делает большой горизонтальный пробел.

Ещё вариант:
\[
    |x|=
    \begin{cases}
    \phantom{-}x, \text{если } x \geqslant 0 \\
    -x, \text{если } x<0
    \end{cases}
\]

Кроме того, для  нумерованых формул \verb|alignedat|  делает вертикальное
выравнивание номера формулы по центру формулы. Например,  выравнивание компонент вектора:
\begin{equation}
 \label{eq:2p3}
 \begin{alignedat}{2}
{\mathbf{N}}_{o1n}^{(j)} = \,{\sin} \phi\,n\!\left(n+1\right)
         {\sin}\theta\,
         \pi_n\!\left({\cos} \theta\right)
         \frac{
               z_n^{(j)}\!\left( \rho \right)
              }{\rho}\,
           &{\boldsymbol{\hat{\mathrm e}}}_{r}\,+   \\
+\,
{\sin} \phi\,
         \tau_n\!\left({\cos} \theta\right)
         \frac{
            \left[\rho z_n^{(j)}\!\left( \rho \right)\right]^{\prime}
              }{\rho}\,
            &{\boldsymbol{\hat{\mathrm e}}}_{\theta}\,+   \\
+\,
{\cos} \phi\,
         \pi_n\!\left({\cos} \theta\right)
         \frac{
            \left[\rho z_n^{(j)}\!\left( \rho \right)\right]^{\prime}
              }{\rho}\,
            &{\boldsymbol{\hat{\mathrm e}}}_{\phi}\:.
\end{alignedat}
\end{equation}

Ещё об отступах. Иногда для лучшей <<читаемости>> формул полезно
немного исправить стандартные интервалы \LaTeX\ с учётом логической
структуры самой формулы. Например в формуле~\ref{eq:2p3} добавлен
небольшой отступ \verb+\,+ между основными сомножителями, ниже
результат применения всех вариантов отступа:
\begin{align*}
\backslash! &\quad f(x) = x^2\! +3x\! +2 \\
  \mbox{по-умолчанию} &\quad f(x) = x^2+3x+2 \\
\backslash, &\quad f(x) = x^2\, +3x\, +2 \\
\backslash{:} &\quad f(x) = x^2\: +3x\: +2 \\
\backslash; &\quad f(x) = x^2\; +3x\; +2 \\
\backslash \mbox{space} &\quad f(x) = x^2\ +3x\ +2 \\
\backslash \mbox{quad} &\quad f(x) = x^2\quad +3x\quad +2 \\
\backslash \mbox{qquad} &\quad f(x) = x^2\qquad +3x\qquad +2
\end{align*}

Посмотрим на систему уравнений на примере аттрактора Лоренца:

\[ 
\left\{
  \begin{array}{rl}
    \dot x = & \sigma (y-x) \\
    \dot y = & x (r - z) - y \\
    \dot z = & xy - bz
  \end{array}
\right.
\]


%\newpage
%============================================================================================================================
\subsection{Нумерованные формулы} \label{subsect1_3_3}

А вот так пишется нумерованая формула:
\begin{equation}
  \label{eq:equation1}
  e = \lim_{n \to \infty} \left( 1+\frac{1}{n} \right) ^n
\end{equation}

Нумерованых формул может быть несколько:
\begin{equation}
  \label{eq:equation2}
  \lim_{n \to \infty} \sum_{k=1}^n \frac{1}{k^2} = \frac{\pi^2}{6}
\end{equation}

Впоследствии на формулы (\ref{eq:equation1}) и (\ref{eq:equation2}) можно ссылаться.

Сделать так, чтобы номер формулы стоял напротив средней строки, можно, используя окружение \verb|multlined| (пакет \verb|mathtools|) вместо \verb|multline| внутри окружения \verb|equation|. Вот так:
\begin{equation} % \tag{S} % tag - вписывает свой текст 
  \label{eq:equation3}
    \begin{multlined}
        1+ 2+3+4+5+6+7+\dots + \\ 
        + 50+51+52+53+54+55+56+57 + \dots + \\ 
        + 96+97+98+99+100=5050 
    \end{multlined}
\end{equation}

Используя команду \verb|\labelcref| из пакета \verb|cleveref|, можно
красиво ссылаться сразу на несколько формул
(\labelcref{eq:equation1,eq:equation3,eq:equation2}), даже перепутав
порядок ссылок \verb|(\labelcref{eq:equation1,eq:equation3,eq:equation2})|.

