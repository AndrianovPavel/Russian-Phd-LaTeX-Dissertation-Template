\chapter{Обзор}
\label{chapter_related_work}

\section{Введение}
\label{rw:introduction}

% Разделить Java и Си?

В настоящее время существует множество различных техник и подходов для поиска ошибок в программном обеспечении.
Однако, универсального инструмента, позволяющего решать задачи любой сложности, создать невозможно.
Но этого мало, до сих пор не выработана единая методика сравнения инструментов, по которой можно было бы оценить степень пригодности некоторого инструмента для решения конкретной задачи или класса задач.

%Существует много разных направлений развития инструментов
Предпринимаются попытки сравнить инструменты, реализованные в рамках одного подхода.
Например, соревнования инструментов статической верификации SV-COMP позволили накопить большой набор входных данных для инструментов статической вериифкации и результаты запусков множества инструментов на этом наборе.
Любой другой инструмент может быть запущен на наборе задач и затем полученные результаты позволят сравнить качество его анализа и скорость с другими инструментами.
Однако, даже такой способ имеет ряд недостатков. 
\begin{enumerate}
\item Сложно сравнивать инструменты различных подходов, например, инструменты динамического анализа требуют для сравнения совсем другие характеристики, чем инструменты статического анализа.
\item Набор небольших тестов не способен показать преимущества и недостатки работы инструментов на больших объемах кода.
\end{enumerate}

Выделим те критерии инструментов верификации, которые являются важными для решения поставленной задачи по проверки корректной синхронизации системного программного обеспечения.
Основным объектом исследования является системное программное обеспечение, которое применяется в критичных областях, в которых цена ошибки очень высока, поэтому одним из основных характеристик должна стать точность метода: он не должен в общем случае пропускать ошибки.
Возможно применение отдельных эвристик в конкретном случае, но общий метод должен иметь возможность гарантировать корректность проверяемой программы.
Вторым важной характеристикой метода верификации должны стать возможности по гибкой настройке баланса между количеством ложных предупреждений и скоростью работы.
С этим же связана масштабируемость: должна быть возможность применения инструмента к реальным программным системам, состоящим из сотен тысяч строк кода.
Кроме того, метод должен адекватно работать со сложными конструкциями языка Си, которые используются в системном программном обеспечении, как то: адресная арифметика, кастирование одних типов к другим и др.

Исходя из этих критериев проведем исследование существующих методов и подходов к анализу программного обеспечения.
Мы не будем рассматривать формальные методы доказательства корректности многопоточных программ, которые основаны на методах дедуктивной верификации, например,~\cite{Le:2015:TRC}.
Хотя такие методы понемногу развиваются, они до сих пор с большим трудом применяются даже к небольшим пользовательским программам. 
Например, в упомянутой статье авторы проводили практическое исследование своего метода на искусственных тестах, типа вычисления чисел Фибоначчи.

\section{Методы динамического анализа многопоточных программ}
\label{rw:dynamic}

Методы динамического анализа подразумевают проверку целевой программы на корректность в процессе ее работы.
Такие методы активно применяется для поиска типовых ошибок, его основное достоинство заключается в низком проценте ложных срабатываний.
Самые простые методы динамического анализа берут свое начало из тестирования и мониторинга.
В этом случае на вход программе подаются некоторые воздействия, и проверяется соответствие выходного результата программы с некоторым идеальным вердиктом.
Ошибки связанные с параллельным выполнением программы являются недетерминированными, поэтому генерация тестов является слишком неэффективным занятием, так как даже на корректном тесте ошибка может проявляться с очень низкой вероятностью.
Тем не менее, такой вариант остается самым простым и может быть достаточно легко автоматизирован.
%Поэтому мы не будем рассматривать методы автоматической генерации тестов, в том числе fuzzing, и далее будем рассматривать такие методы динамического анализа программ, которые позволяют определить возможность состояния гонки на основе внутреннего состояния программы.
%Направляемое тестирование?

\subsection{Методы динамического анализа многопоточных программ на основе векторных часов}

Для повышения шанса обнаружения состояния гонки применяются более сложные методы динамического анализа, основанные на инструментировании исполняемого кода и наблюдении за внутренним состоянием программы в процессе ее выполнения.
Такие подходы основываются на идее векторных часов Лампорта~\cite{Lamport} для определения связи Happens-Before.
Основная мысль этого подхода заключается в том, что все события в одном потоке являются упорядоченными, а значит, их можно сопоставить с некоторыми векторными часами, каждая компонента которых соответствует отдельному потоку.
Синхронизация между потоками может быть представлена, как синхронизация между часами соответствующих потоков. 
Тогда, если для некоторых событий можно установить, что одно из них было строго раньше другого (связь Happens-Before), они не могут образовывать состояние гонки.
Стоит отметить, что такой подход позволяет обнаруживать потенциальные состояния гонки, которые не произошли при выполнении, однако это влечет за собой возможные ложные срабатывания.
Основными проблемами подхода на основе векторных часов являются большое количество потенциально разделяемой памяти, которую необходимо отслеживать, поэтому различные инструменты предлагают свои варианты решения данной проблемы.
Далее, кратко опишем такие оптимизации в различных инструментах.

% и некоторые оптимизации для того, чтобы сократить накладные расходы.
%%В основном, она заключается в сэмплинге (sampling), то есть в уменьшении объема памяти, за которой производится слежение.
%С помощью векторных часов строится отношения happens-before для всех операций.
%Если для двух доступов к памяти невозможно указать порядок, то есть, построить отношение happens-before, выдается предупреждение о возможном состоянии гонки. 
%Дальше применяются различные техники и оптимизации для сокращения времени работы целевой программы и требуемой для анализа памяти.

%Инструменты динамического анализа устроены следующим образом: сначала инструментируется исходный код программы, и в него добавляется код, реализующий некоторый метод поиска состояний гонки.
%Далее, код программы компилируется, запускается и в процессе эксплуатации программы производится анализ ее поведения на предмет наличия определенных дефектов, в том числе состояний гонки.
% Рассмотрим основные инструменты динамического анализа, предназначенные для поиска состояний гонок.


В статьях ~\cite{Flanagan:2009:PLDI, Flanagan:2009} описывается следующая оптимизация.
Так как запись информации обо всех действиях в программе занимает слишком много времени, то сохраняется только информация о самых последних доступах к переменной.
Менее 1\% случаев гонок требуют полного сохранения векторных часов, в остальных случаях достаточен более легковесный подход.
Используется понятие эпоха - это идентификатор векторных часов и номер потока.
Инструмент позволяет адаптивно выбирать, сохранять ли конкретное значение векторных часов для некоторой переменной или только эпоху.
Такой подход позволяет уменьшить накладные расходы, не потеряв точности.  
%Состояние потока включает в себя векторные часы, значение векторных часов для освобождаения каждой блокировки, эпоху или вектор часов для последнего чтения каждой переменной и эпоху последней записи в каждую переменную. 
%Требуемое для анализа время, в среднем, в 4-5 раз больше, чем для работы исходной программы.
%Объем требуемой памяти возрастает на 20-30\%.

В статьях ~\cite{Marino:2009:PLDI, Marino:2009} описан инструмент LiteRace, который использует оптимизацию, основанную на гипотезе <<холодных регионов>>: предполагается, что состояния гонки, скорее всего, проявятся в редко исполняемых участках кода (т.н. <<холодных>>), так как на часто исполняемых они уже исправлены.
%При таком предположении можно уменьшить количество памяти, за которой происходит слежение.
Таким образом, за <<горячими>> участками слежение почти не ведется, а доступы к памяти из холодных участков отслеживаются полностью.
При этом <<горячие>> участки кода вычисляются отдельно для каждого потока.
%В среднем, накладные расходы составляют 28\% времени работы.
%Это в 25 раз меньше, чем если бы обрабатывались все обращения к памяти.

Статьи~\cite{Bond:2010:PLDI,Bond:2010} представляет еще один инструмент - PACER, который использует следующую оптимизацию: доступы к памяти учитываются только в период выборки (англ. sampling period).
%Инструмент Pacer дает гарантии того, что существующая гонка будет найдена с вероятностью равной уровню выборки (sampling rate).
Pacer случайно включает и выключает слежение за динамическими операциями (англ. sampling period).
Во время слежения он автоматически подбирает уровень слежения (англ. sampling rate) такой, чтобы вероятная ошибка нашлась с заданной вероятностью.
%Во время периода слежения, Pacer обрабатывает все операции, связанные с синхронизацией, и все доступы к переменным.
%В оставшееся время, инструмент следит только за теми переменными, которые он выбрал.
%В итоге для уровня выборки 1-3\% накладные расходы составляют 52-83\%.
Однако, такой метод имеет два важным недостатка:
\begin{enumerate}
\item можно пропустить важные happens-before дуги, которые приведут к ложному предупреждению;
\item при уровне выборки r число найденных состояний гонок будет лишь $r^2$. 
\end{enumerate}
%LiteRace инструментирует все операции синхронизации, чтобы решить первую проблему.
%Для решения второй он ищет состояния гонок только в холодных участках кода.
%Еще важное отличие LiteRace в том, что он детерминирован, а Pacer намеренно использует случайные значения, чтобы найти состояния гонки, которые были пропущены в предыдущих запусках.

Статья~\cite{Serebryany:2011} представляет улучшение метода, реализованного в инструменте ThreadSanitizer-Valgrind~\cite{TSan}, представленного ранее.
Основная часть логики метода осталась той же самой, однако в следствие использования компилятора LLVM удалось повысить скорость работы, а также портируемость, с которой были большие проблемы. 
%TSan-LLVM использует инструментацию во время выполнения программы, что приводит к замедлению ее работы в 2-3 раза.
%Сам алгоритм анализа может быть представлен в виде конечного автомата, который обрабатывает произошедшие в программе события, такие как чтение, запись, захват блокировки и др.
Для определения состояния гонки используется и Lockset алгоритм, и Happens-Before, что позволяет повысить точность. 
Для того, чтобы уменьшить расходы на анализ, применяются выборочное слежение за доступами к памяти (sampling) и гипотеза <<холодных регионов>>.
%В отличие от LiteRace, который применяет ту же идею, TSan всегда выполняет инструментированный код, но если для данного потока счетчик выполнений данной операции выше уровеня упрощения (sampling rate), то информация о доступе к памяти игнорируется.
%Второе важное отличие заключается в том, что LiteRace считает холодными участками кода целые функции, TSan оперирует на уровне базовых блоков, что уточняет анализ.
%Основной недостаток инструментации во время выполнения - это то, что могут быть потеряны ошибки, находящиеся в коде, которые не компилируется: системные библиотеки или JIT код. 
Сравнение подхода показало, что, в среднем, применение инструментации позволяет ускорить работу в 2-3 раза по сравнению с оригинальным TSan-Valgrind и в 10 раз по сравнению с другими инструментами, такими, как Valgrind. Однако, не сравнивалось число найденных ошибок. 


% Static-Dynamic


\subsection{Методы статико-динамического анализа многопоточных программ}

Многие динамические инструменты используют для оптимизации своей работы простой статический анализ, который предоставляет некоторое множество потенциальных обращений к памяти, которые могут участвовать в состоянии гонки.
Несмотря на то, что используемый анализ может быть очень простым и выдавать большое число обращений к памяти, такая оптимизация способна сильно повысить эффективность анализа, так как все равно способна исключать из рассмотрения определенное множество областей памяти.
Такие фреймворки устроены похожим образом.
Сначала запускается достаточно быстрый статический анализ, который определяет ту память, которая должна учитываться в процессе динамического анализа, затем запускается динамический анализ, который, выполняя программу, следит за выделенными областями памяти. 
В статье~\cite{Qi:2009:MPE} как раз и описан такой статико-динамический подход.
Кроме общего описания в статье приведено множество оптимизаций для повышения эффективности и точности как статического, так и динамического анализов.
В частности, описана интересная оптимизация памяти для динамического анализа. 
Основной алгоритм Lockset требует сохранять множество доступов к переменной для последующего вычисления множества общих блокировок.
Авторы высказывают мысль, что на самом деле все доступы подряд сохранять не обязательно.
Нужны лишь множества с минимальными множествами блокировок. То есть, если уже сохранен доступ с одной блокировкой, то не нужно хранить информацию о другом доступе, которое было защищено двумя блокировками, если одна из них - та же самая.

В статье~\cite{Yoga:2016:PDR} авторы добавили третью стадию: точный алгоритм статического анализа, который проверяет потенциальные состояния гонки, которые могли бы возникнуть при другом расписании выполнения потоков.
Этот алгоритм записывает формулу пути, которую затем разрешает с помощью SAT-решателя.
Состояния гонки, найденные во время динамического анализа являются истинными ошибками, а предупреждения, найденные во время третьей стадии - лишь потенциальными ошибками, однако такой подход позволяет получать больше информации за один запуск инструмента анализа.

В статье~\cite{DataCollider} представлен оригинальный способ поиска гонок в ядре ОС.
%Одна из проблем поиска гонок в ядре операцонной системы заключаются в том, что ядро ОС оперирует более низким уровнем абстракции, чем пользовательские приложения.
%Вторая важная особенность - это проблема поиска состояния гонки в случае, когда обращение к данным происходит от аппаратуры.
%И, наконец, многие динамические инструменты значительно замедляют работу программы. К тому же они используют инструментацию, которую довольно сложно применить к ядру ОС. 
DataCollider расставляет несколько точек прерывания на случайные доступы к памяти.
Когда программа доходит до них, выполнение останавливается, сохраняется значение той ячейки памяти, куда происходит обращение, и спустя какое-то время проверяет, что значение не изменилось.
В ином случае фиксируется состояние гонки.
%Для того чтобы получить информацию о потоке, из которого произошел второй доступ к памяти, используются аппаратные прерывания, которые ставятся на доступ к конкретной области памяти.
%Значительное преимущество инструмента состоит в том, что нет необходимости разбираться в сложных примитивах синхронизации ядра.
Не все состояния гонки ведут к ошибкам. Так, эксперименты с DataCollider показали, что только 10\% предупреждений соответствует истинным ошибкам. 
%Чтобы уменьшить число ложных предупреждений используется некоторая обработка информации после анализа.
%Для определения точек расстановки прерываний DataCollider дезассемблирует исполняемый файл и получает множество всех областей памяти.
%Далее, используя простые алгоритмы статического анализа, он отсеивает те локальные области памяти, доступ к которым никак не может привести к состоянию гонки.
%Из оставшихся выбираются те, за которыми будет следить инструмент, и на них расставляются точки прерываний.
%В случае, если во время работы инструмента была найдена ошибка, то соответствующая ей точка прерывания удаляется и выбирается новый доступ к памяти.
%Во время работы DataCollider следит за количеством прохождений выбранных точек прерываний.
%Если оно больше или меньше, чем некоторое целевое значение, точка останова может быть удалена, и выбрана новая.
DataCollider был применен к нескольким драйверам ОС Windows. Было найдено 38 состояний гонки. При этом замедление работы было всего 10-15\% процентов. 

Развитие идеи DataCollider было продемонстрировано в статье~\cite{DRDDR}.
Инструмент DRDDR был применен к операционной системе Linux, в которой запускались два набора тестов. 
Инструмент показал очень низкий уровень накладных расходов в 0,1\%, но при этом смог обнаружить только несколько безобидных состояний гонки.
%Основной оптимизацией стало использование 
%TODO оценка и перспективность

Статико-динамический подход имеет определенные перспективы, позволяя сочетать в себе плюсы нескольких подходов.
Такие подходы неплохо масштабируются, и способны успешно применяться к системному коду.
Однако, даже такие методы демонстрируют достаточно невысокий процент истинных ошибок, что показали результаты DataCollider.
Кроме того, они также не могут гарантировать отсутствие ошибок в программе.
При этом возникают традиционные проблемы, связанные с настройкой тестового окружения, что в случае операционной системы приводит к определенным требованиям к оборудованию.
Одним из возможных направлений развития таких подходов - является использование виртуальных машин, для которых задача настройки тестового окружения значительно упрощается. 
Такие методы сейчас активно развиваются, однако, основной их целью по-прежнему остается проверка некоторого множества уже найденных предупреждений.

%В статье~\cite{Sadowski:2009} представлен инструмент для динамической проверки в Java программах двух свойств:
%1) Отсутствие конфликтов между потоками внутри одной транзакции.
%2) Потоки внутри транзакции не должны влиять на потоки вне ее. 
%Для проверки первого условия используется алгоритм векторных часов, который строит отношение happens-before внутри транзакции. Для проверки второго условия тот же самый граф happens-before строится для транзакций в целом. 
%Конфликтом называется ситуация, в которой происходит обращение к одним и тем же данным из разных потоков или захват/освобождение одной и той же блокировки.
%Кроме того, к конфликтам относятся операции в потоке до его создания (fork) или после завершения (join). Транзакцией является некоторая последовательность операций. 
%Инструмент принимает на вход Java байткод. Он был проверен на восьми тестах JavaGrande, каждый тест был размером около 1000 строк кода. Замедление времени работы составило около 10 раз. 

%Статья~\cite{Eslamimehr:2014} представляет динамический инструмент для поиска состояний взаимной блокировки в Java программах.
%Инструмент сначала выполняет все потоки на основании некоторого случайного расписания, а потом на основании символически построенных ограничений пытается направить выполнение программы таким образом, чтобы произошло состояние взаимной блокировки.

\subsection{Узкоспециализированные методы динамического анализа многопоточных программ}

На практике часто оказывается, что под каждую задачу, связанную с анализом системного программного обечпечения, эффективнее разработать собственный инструмент.
Так, в статьях~\cite{Fonseca:2010,Fonseca:2011} представлен опыт поиска ошибок в сервере MySQL.
Сначала были проанализированы часть исправлений, сделанных в процессе разработки от версии 3.x до версии 6.х.
Результаты показали, что ошибки, связанные параллельным выполнением становятся все более и более распространенными.
Состояние взаимной блокировки вызывали 40\% ошибок. 28\% всех ошибок приводили к падению системы, а 15\% - к предоставлению неверных данных пользователю.
15\% всех багов приводили к ошибки не сразу, т.н. “скрытые” баги, причем 92\% из них впоследствии проявляют себя тем, что выдают пользователю невереные данные - это семантические баги.
Далее авторы рассказывают о своем опыте поиска гонок с помощью инструмента PIKE.
Метод поиска гонок основан на том, что несмотря на внутренний параллелизм, сервер ведет себя так, как если бы все запросы выполнялись последовательно. 
Каждое параллельное выполнение сравнивается со всеми возможными его линеаризациями. Если ни одна из них не соответствует реальной трассе, фиксируется ошибка. 
Для того, чтобы найти скрытые ошибки, которые повреждают структуру данных, а не логику выполнения, необходимо применить описанный метод не в конце выполнения, а для каждого внутреннего состояния программы.
%Отдельный вопрос, как понять и описать это состояние. Это задача тестировщика, либо разработчика, который должен явно указать, что считать состоянием.
%Традиционный подход к динамическому анализу многопоточных программ основан на стрессовом тестировании и генерации шума.
%Однако он имеет три ограничения. Во-первых, этот подход не систематичен, то есть не позволяет избежать анализа лишних или похожих событий.
%Во-вторых, в таком подходе невозможно выделить приоритетные события, которые, скорее всего, приведут к ошибке.
%И, наконец, даже если ошибка обнаружена, ее крайне сложно воспроизвести.
Инструмент PIKE пытается обойти эти ограничения с помощью алгоритма случайного планирования. При старте программы планировщик выбирает случайный приоритет для каждого потока. В каждый момент времени активен поток с наибольшим приоритетом. Приоритет случайным образом меняется в некоторых случайных точках программы. 
%Для оценки результатов анализировался MySQL сервер, развернутый на кластере из 15 машин.
%Было проведено 1550 тестов, на каждом из которых было исследовано до 400 различных переключений контекста, используя описанный алгоритм планирования.
%Это заняло более месяца.
%Были найдены две ошибки, которые могли вызывать падение сервера, и 10 ошибок, которые приводили к некорректной работе сервера.
%Примерно треть всех тестов привела к ложным предупреждениям об ошибках, однако, оказалось, что большинство из них связано с работой с различными кэшами.

Повысить эффективность динамических подходов возможно за счет сужения класса определяемых ошибок.
В статьях~\cite{Park:2009:ASPLOS,Park:2009:SIGARCH,Park:2009} описывается подход к динамическому поиску конкретного класса ошибок в многопоточных программах - нарушениям атомарности операций.
Чтобы уменьшить объем анализируемых данных, все возможное множество вариантов переключения контекста ограничивается теми, которые соответствуют несериализуемым взаимодействиям (англ. unserializable interleavings).
Для таких взаимодействий не существует никакого последовательного эквивалента выполнения участвующих операций.
%Из этого множества нужно исключить невыполнимые варианты взаимодействия, например, защищенные одной и той же блокировкой.
%Инструмент умеет определять часто возникающие ситуации и фокусируется на редких. Анализ делится на несколько стадий.
%Сначала запускаются несколько тестов для профилирования, затем определяются все возможные нарушения атомарности, после чего выделяются достижимые. Далее, полученное множество упорядочивается по частоте возникновения.
Инструмент запускался на таких промышленных программных системах, как MySQL, Apache, Mozilla и др.
Затраченное время на анализ оказалось в 10-1000 раз меньше, чем у других подходов. 
Однако, следует помнить, что такая эффективность достигается за счет сужения класса искомых ошибок.

%В статье~\cite{Vafeiadis:2010} вводится понятие линеаризуемости.
%Линеаризуемость - это свойство корректности параллельных реализаций абстрактных структур данных (стек, очередь, и др.).
%Оно требует, чтобы каждая операция была атомарна и удовлетворяла заданной функциональной спецификации. Один из способов доказать линеаризуемость - это определить точки линеаризации программы, в которых сосредаточена основная функциональность.
%В статье предложен алгоритм проверки линеаризуемости.
% Инструмент был проверен на восьми тестах, в среднем каждый занимал 100 строк кода. 

В статье~\cite{Kusano:2016:FCT} был предложен модульный подход для построения предикатной абстракции.
Подход был успешно применен к различным примерам как из набора соревнований sv-comp, так и на примерах, построенных на основе драйверов операционной системы Linux.
Этот подход был применен для анализа низкоуровневого кода, в котором присутствуют прерывания (even-driven systems)~\cite{Sung:2017}.
%TODO {Подробнее и выводы!}

Основные особенности методов динамического анализа заключаются в следующем:
\begin{enumerate}
\item Рассмотренные инструменты динамического анализа ориентированы, в основном, на пользовательские приложения. 
Успешное применение к системному программному обеспечению возможно при сужении класса рассматриваемых ошибок.
\item Вероятностный характер алгоритмов не позволяет гарантировать отсутствия ошибок.
\item Масштабируемость зависит больше не от объема кода, а от объема инструментированного кода, то есть кода, в котором производится поиск состояний гонки. 
\item В случае системного программного обеспечения могут возникнуть определенные требования к оборудованию.
%\item При проведении динамического анализа рассмотренными инструментами необходимы пользовательские воздействия, то есть процесс не является полностью автоматическим.
\end{enumerate}

Данные особенности позволяют заключить, что методы динамического анализа не являются достаточным способом поиска состояний гонки в программном обеспечении, которое предъявляет повышенные требования к надежности. 
Кроме того, эффективность таких методов существенно снижается при анализе сложного программного обеспечения.


\section{Методы статического анализа многопоточных программ}
\label{rw:static}

В данном разделе под статическим анализом понимаются такие методы, которые анализируют исходный код программы без ее реального выполнения и характеризуются высокой скоростью работы за счет применения различных фильтров и эвристик.
Такие методы традиционно применяются на больших программных системах.
Он отличается большим набором проверенных ситуаций, чем динамический анализ, но также не могут претендовать на формальное доказательство отсутствия ошибок.
В основном, статический анализ применяется для поиска типовых ошибок, таких как некорректная работа с памятью.
Поиск состояний гонки является достаточно трудоемкой задачей по сравнению с поиском таких ошибок, поэтому большая часть статических анализаторов не предоставляет возможность поиска ошибок, связнных с некорректным взаимодействием потоков.
Тем не менее, существуют различные академические инструменты статического анализа, позволяющие находить состояния гонки.

Статья~\cite{Pratikakis:2011} представляет инструмент Locksmith для статического поиска гонок.
Locksmith реализован на основе библиотеки CIL~\cite{CIL}, которая используется для разбора исходного кода.
Инструмент последовательно и независимо друг от друга проводит несколько стадий анализа, собирая информацию о потоках данных, потоке управления, разделяемых данных и используемых примитивах синхронизации.
Такое разделение анализов положительно сказывается на скорости, однако инструмент сильно теряет в точности анализа.
%На первой фазе анализа Locksmith обходит граф потока управления и создает две ключевые абстракции: ограничения потока меток (label flow constraints), чтобы смоделировать поток данных в программе, и ограничения потока управления (control flow constraints), чтобы смоделировать последовательность действий и связать ее с первым типом ограничений.
%Анализ потока меток чувствителен к полям структур (field-sensitive), это значит, что каждое поле моделируется независимо от других.
%Возникают различные проблемы с моделированием указателей типа void, и в статье было рассмотрено несколько вариантов их решения.
%Чтобы достигнуть контекстной чувствительности, информация о вызове функции добавляется в граф потока меток.
%Ограничения потока управления представляют собой граф потока управления каждого потока.
%Следующая стадия называется анализ разделяемости данных, на которой определяются те области памяти, которые доступны из нескольких потоков.
Например, множество разделяемых данных вычисляется для всей программы сразу. 
То есть, если некоторая память сначала является локальной, а после некоторых действий становится разделяемой, то эта память будет считаться разделяемой в каждой точке программы.
Другой важной особенностью является то, что инструмент предполагает работу только с полностью доступным кодом.
Это необходимо для того, чтобы можно было определить область памяти, на которую указывает каждый из указателей.

%Далее происходит пересечение множества захваченных блокировок для каждого доступа к разделяемой переменной.
%После этого шага возможен вывод предупреждений или применение дополнительных эвристик.
Как и все инструменты статического анализа, Locksmith работает очень быстро, характерное время работы составляет 1с на 1000 исходного строк кода.
Но при этом находит достаточно много ложных предупреждений, так, для драйверов ОС Linux истинных ошибок было всего 9\%.
Большинство ложных срабатываний связано с неточноностью анализа разделяемых данных.

Таким образом, можно заключить, что инструмент, хотя и является достаточно масштабируемым, не способен обеспечить необходимую точность и конфигурируемость анализа.

Одним из инструментов, которые был применен к большому объему системного программного обеспечения является Relay~\cite{Relay}, который основан на алгоритме Lockset.
Он вычисляет некоторое <<суммарное действие>> функции (англ. summary) в терминах изменений множества захваченных примитивов синхронизации и доступов к памяти относительно точки входа в функцию.
Модель потоков является достаточно простой: считается, что все функции могут быть выполнены параллельно друг с другом.
Определение множества возможных алиасов происходит с помощью анализа Стинсгаарда~\cite{Steensgaard:1996}.
Авторы применили инструмент модулям операционной системы Linux, при этом получили более 5000 предупреждений.
Такое количество предупреждений проанализировать вручную невозможно, поэтому авторы выбрали некоторое подмножество, проанализировали его, а затем разработали набор неточных фильтров, которые сокращают количество предупреждений.

Похожим образом действуют авторы IteRace~\cite{Radoi:2015:ETS}.
Сначала определяются алиасы с помощью анализа Андерсена, затем для каждой области памяти проверяются синхранизационные примитивы, что позволяет вычислить множество потенциальных состояний гонки.
Затем применяются различные фильтры, которые позволяют сократить количество ложных сообщений об ошибке.

Еще один похожий инструмент представлен в статье~\cite{Di:2016:ADD}.
В нем авторы также с помощью простого анализа находят множество доступов к данным, а затем применяют некоторые фильтры, которые позволяют исключить ложные сообщения о состояних гонки.
Самой интересной идее авторов является расширение анализа указателей Андерсена на многопоточный случай.
Для апробации авторы взяли инструмент TSan и применили его к небольшому набору пользовательских программ. 
А затем применили его же с подсказками от своего инструмента. 
В статье~\cite{Sui:2016} тот же инструмент сравнивается относительно довольно старого анализа алиасов.

А в статье~\cite{Zhou:2018} было предложено использовать векторные часы в статическом анализе, при этом сам фреймворк остался тем же.
Анализ алиасов снова сравнивался с некоторым старым анализом, а результаты поиска гонок сравнивались с результатами инструмента Lockset.
%Вопросы остаются

% --Алиасы

Мы видим, что очень не многие исследователи пытаются разработать подход, применимый к системному программному обеспечению. 
В основном, усилия тратятся на совершенствовании анализа алиасов и переносу его на многопоточный случай.
Важной проблемой, которая возникает при анализе реального программного обеспечения, является определение равенства областей памяти.
%Если в методах проверки моделей разделяемые данные программы моделируются только с помощью глобальных переменных, то в методах статического анализа большое внимание уделяется анализу алиасов.
В некоторых статьях, представляющих методы поиска состояний гонки, акцент смещен в сторону описания методов анализа алиасов, а затем на полученном множестве алиасов применяется простой алгоритм Lockset для определения потенциальных состояний гонки. 
Такие подходы не являются эффективными с точки зрения поиска состояний гонки, так как точный анализ алиасов требует значительных ресурсов: как времени, так и памяти.

В статье~\cite{Kahlon:2009:SDR} для быстрого определения множества алиасов рассматривается идея применения разбиения Стинсгаарда~\cite{Steensgaard:1996}. 
Указатели могут быть алиасами указателей только из своего подмножества.
Так как разбиение Стинсгаарда обычно невелико, то определять точное равенство указателей, чтобы доказать корректность алиасов, приходится нечасто.
Кроме того, анализ необходимо выполнять для всех указателей, хотя на самом деле разделяемыми являются только некоторые из них, поэтому классический анализ алиасов становится неэффективным.

В статье ~\cite{Seidl:2009} предложено два варианта анализа алиасов, которые основаны на анализе регионов.
Цель анализа регионов - показать, что выделенная на куче память корректно разделена на непересекающиеся блоки.
Первый подход основан на сложном анализе размера структур данных. Этот подход очень плохо масштабируется на большие программы.
Другой подход работает с динамически выделенными объектами, как с блоками памяти, связанными с абстрактными состояниями.
В этом случае возникают проблемы с анализом областей памяти, выделенных в одной точке программы.
В статье описан анализ регионов достаточно быстрый и точный для программ, работающих с непересекающимися областями памяти.

При применении инструмента к модулям ОС Linux авторы столкнулись с проблемами обработки структур, содержащих массивы, арифметикой указателей, преобразованием типов (кастированием).
Были попытки расширить возможности анализа, например, предположением, что указатель может указывать не только на начало блока памяти. 
Инструмент запускался на 9 драйверах. Число разделяемых переменных оказалось невелико.

Таким образом, можно сказать, что точный анализ алиасов неприменим к большим программным системам, в частности, к ядру операционной системы, так как число разделяемых переменных будет достаточно большим, а значит, сам анализ алиасов будет требовать неприемлемое количество времени.

%-- Классы ошибок

%Например, в статье ~\cite{Naik:2009} представлен алгоритм поиска состояний взаимной блокировки для Java программ.
%Инструмент производит k-объектный, контекстно-чувствительный анализ исходного кода, строит граф вызовов и граф указателей (points-to).
%Выделяются все возможные места, в которых возможна блокировка, то есть состояния, в которых захвачены некоторые блокировки и ожидается их освобождение.
%Для каждой пары таких состояний проверяется, является ли эта пара взаимной блокировкой.
%Важно замететить, что алгоритм является неточным.
%Первое ограничение в том, что поиск взаимных блокировок ведется между парами потоков. Большее количество не учитывается.
%Второе важное ограничение - это учет синхронизации только на основе блокировок.

Высокую эффективность показывают инструменты статического анализа, которые нацеливаются на поиск очень узкого класса ошибок.
Очень интересна работа~\cite{Xiong:2010}, которая посвящена поиску неявных типов синхронизаций.
В статье проведен анализ нескольких больших программных продуктов на предмет наличия в них неявнных или специальных (ad hoc) видов синхронизации, например, таких как ожидание в цикле, пока некоторая переменная не примет определенное значение.
Важно заметить, что если в программе определяется некоторая функция, которая используется для синхронизации, она не считается неявной.
В процессе исследования были получены следующие результаты.

\begin{itemize}
\item Каждая изученная параллельная программа использует неявную синхронизацию.
\item В основном, все неявные типы синхронизации представляют собой бесконечные циклы, выход из которых возможен при специальном условии. Но несмотря на это, такие неявные синхронизации тяжело определять.
\item Во многих случаях неявный способ синхронизации приводил к ошибкам. Обычно это выражалось во взаимной блокировке или бесконечному ожиданию в цикле. 
\item Из-за того, что многие инструменты не могут определить неявную синхронизацию, пропускается большое число ошибок. 
\end{itemize}

Для помощи разработчикам был создан инструмент, который аннотирует синхронизационные циклы.
Было предложено два алгоритма.
Первый алгоритм определяет условие выхода из цикла и с помощью решателя доказывает, что это условие нарушается только после действий другого потока.
%Эксперименты показали, что обычно синхронизация устроена достаточно просто.
%В некоторую разделяемую переменную явно присваивается число, при том один раз, проверяется также обычно на равенство конкретному значению
%Поэтому можно использовать более простые техники, чем решатели.
В качестве второго алгоритма был предложен метод на основе распространения ограничений.
В результате каждый найденный синхронизационный цикл аннотируется. Такой результат может быть использован в двух аспектах.
Во-первых, разработчики могут вручную просмотреть каждый цикл и понять, является ли он ошибкой или нет.
На проведенных тестах инструмент верно нашел 96\% неявных способов синхронизации. При этом число ложных сообщений об ошибках было всего 6\%.
Во-вторых, другие инструменты поиска гонок могут использовать данные аннотации для более точного анализа.
Так, эксперименты с Valgrind показали, что число ложных предупреждений сокращается на 43-86\%. 

В работе~\cite{Smith:2011:LGS} авторы концентрируются на поиске неправильного использования глобальных переменных, которое может привести к ошибкам.
Было проведено экспериментальное исследование, выделено три категории неправильного использования и создан инструмент для поиска таких случаев.
Кроме того инструмент пытается помочь разработчикам и автоматически пытается преобразовать код таким образом, чтобы вместо глобальных переменных использовались локальные параметры.

В работах~\cite{FreeRTOS,RacesFreeRtos} представлен подход к поиску состойний гонки в ядрах операционных систем на примере FreeRTOS. 
Однако, большую часть статей занимает описание построения окружения для ядра, то есть, описание того, что может выполняться параллельно. 
Дело в том, что в ядре имеется много активностей, которые выполняются после наступления некоторого события. 
Для статического анализа необходимо искусственно создать некоторую \textit{main}-функцию, в которой будут описаны те активности, которые могут выполняться параллельно. 
Например, задана взаимосвязь между обработчиками прерываний, отключением прерываний и функции приостановки работы (suspend). 
Эта взаимосвязь не выражается с помощью стандартных POSIX API, поэтому и нужна специфическая модель окружения и анализ, учитывающий особенности ядра. 
Сам анализ многопоточных программ является расширением анализа явных значений на множества (вариация анализа многоугольников).
А значит, снова возникает проблема потери точности анализа при любых операциях с указателями.

Многие рассмотренные методы ограничиваются лишь корректным вычислением алиасов, и задача поиска гонок отходит на второй план.
Эффективные методы, которые применяются при решении практических задач, не подходят для доказательства корректности и позволяют быстро обнаруживать потенциальные ошибки.
При этом системное программное обеспечение накладывает определенные требования, поэтому на практике часто применяются специальные решения, которые нацеливают более-менее общий метод Lockset на конкретный исходный код.
Таким образом, основной задачей становится не разработка эффективного метода, а адаптация существующего подхода.

%\newpage
%============================================================================================================================

\section{Методы статической верификации многопоточных программ}
\label{rw:bmc}

Статическая верификация отличается от легковесных методов статического анализа более формальным подходом к проверке корректности программы.
За счет этого возможно получения доказательства отсутствия определенного класса ошибок в некоторых заранее заданных предположениях.
%
%Мы не рассматриваем методы классической проверки моделей, которые предполагают написания модели программы человеком. 
%Мы также не рассматриваем методы статической верификации нацеленные на программы, использующие слабые модели памяти~\cite{Alglave:2013,Zhang:2015,Abdulla:2017}. 
%Такие модели памяти нашли свое отражение в архитектурах процессоров MIPS, POWER.
%
Основная идея методов статической верификации программ заключается в автоматической построении модели программы по ее исходному коду, а затем в проверке этой модели на соответствие некоторой спецификации.
Для этого возможно применение различных методов, таких как абстракция, уточнение абстракции по контрпримерам (англ. CEGAR), ограничиваемая проверка моделей.
Так или иначе строится конечный путь к ошибке, затем этот путь трансформируется в логическую формулу, которая проверяется на выполнимость с помощью специального компонента: решателя (англ. solver).
Это позволяет исключить многие ложные предупреждения, не потеряв при этом реальные ошибки, в отличие от методов статического анализа.

Основными плюсом данного подхода является строгость доказательства и, как следствие, низкий процент ложных сообщений об ошибках.
Минусом подхода является высокое требование к ресурсам.
%Кроме того, одним из ограничений подхода является отсутствие поддержки операций и объектов, которые могут привести к потенциально бесконечному множеству состояний.
%К ним относятся, например, циклы, рекурсия, а также операция с динамически выделяемой памятью. 

Первыми, как наиболее простые, стали развиваться методы, рассматривающие все возможные чередования потоков.
Для применения таких методов к многопоточным программам необходимо упорядочить последовательность операций во всех потоках, чтобы иметь возможность построить логическую формулу пути.
Для этого необходимо определить точки, в которых происходит переключение выполнения операций одного потока на операции другого потока.
%Это число переключений контекста еще называется чередованием потоков (англ. interleavings).
Наблюдение, что ошибки проявляются уже при небольшом числе переключений контекста, позволило ограничить число переключений некоторым небольшим фиксированным K.
В условиях ограниченного количества переключений (англ. context bounded switches) применяются различные техники и оптимизации для сокращения пространства состояний. 

Многие методы моделируют взаимодействие между потоками только с помощью операций над глобальными переменными.
В этом случае переключение потока имеет смысл рассматривать в случае, если в текущем состоянии происходит доступ к глобальной переменной.
Такая идея используется, например, в статье~\cite{Cordeiro:2011}. В ней же описаны еще несколько оптимизаций.

Ленивый подход предполагает, что дерево достижимости обходится в глубину, собираются все полученные ограничения для пути и для каждого узла дерева вызывается обычная процедура для ограниченной проверки модели.
Подход с записью расписания (schedule recording) добавляет к формуле ограничения на планировщик, что позволяет объединить все возможные варианты исполнения программы объединяются в одну формулу и отдать решателю.
Расширяющийся подход (under-approximation and widening approach) основан на том, что сначала строится формула для частного случая взаимодействия процессов, и она проверяется решателем.
Если найдена ошибка, значит, более общая модель уже не нужна. Иначе, постепенно отбрасываются ограничения на планировщик, тем самым покрывается все больше вариантов параллельной работы. 

В уже упомянутой статье~\cite{Cordeiro:2011} основным результатом, на котором акцентируется внимание является то, что предложенные оптимизации позволяют анализировать программы с 10 переключениями контекста, в то время, как похожие инструменты (в статье упоминаются CHESS~\cite{Musuvathi:2007} и SATABS~\cite{SATabs}), способны анализировать лишь 5 переключений контекста.
При этом тестовый набор составлялся авторами статьи и включал в себя 21 рукописную программу. 

В статье ~\cite{Lahiri:2009} авторы представляют инструмент для проверки моделей для применения к низкоуровневому системному коду.
Сначала производится трансляция исходной Си программы в программу на языке Boogie~\cite{boogiePL} с помощью инструмента HAVOC~\cite{Chatterjee:2007}.
Это делается для того, чтобы избавиться от таких конструкций, как динамическое выделение памяти, арифметика указателей, преобразование типов. Далее, параллельная программа преобразуется в последовательную, и для нее уже строятся формулы, которые проверяются с помощью SMT решателя.
Для того чтобы повысить масштабируемость метода, применяется слайсинг по полям структур.
Такая идея базируется на предположении, что для проверки конкретного свойства необходимо наблюдение за очень небольшим количеством полей.
Построение множества отслеживаемых полей производится с помощью метода CEGAR. 
Для моделирования переключения контекста для карты памяти глобальных переменных создаются K копий. И переключение контекста моделируется переключением работы с одной картой памяти на другую.
Инструмент запускался на четырех реальных драйверах ОС Windows.
Время работы составляло порядка часа на программу из 600 операторов (locations). 

В продолжении этой статьи~\cite{Ghafari:2010} представлено довольно объемное экспериментальное исследование применения инструмента на реальном исходном коде.
К сожалению, не очень понятно, что именно за код был взят для экспериментов.
Было проведено значительное количество запусков инструмента с различными вариантами преобразований в последовательную программу, с различным количеством активных потоков, количеством переключений контекста и различным количеством операторов в каждом из потоков.
Общий вывод оказался следующим: при количестве потоков больше трех или количестве переключений контекста больше четырех инструмент неприменим, так как время анализа превосходит несколько часов.
При этом количество операторов в программе измеряется всего несколькими десятками.

В статье~\cite{Basler:2009} авторы представляют идею абстракции по программному счетчику.
%Статья посвящена важной задаче исследования пространства состояний, основанных на BDD-представлении для логических программ.
%Проблема комбинаторного взрыва локальных состояний решается с помощью метода CEGAR. 
%Сначала исходная программа транслируется в логическую, в которой все переменные могут принимать только значения {0,1}.
%Количество переменных получившейся программы потенциально может быть бесконечно. 
%Для снижения затрат ресурсов используется абстракция программного счетчика (counter abstraction).
Вводится понятие эквивалентности глобальных состояний относительно перестановки локальных состояний и для каждого локального состояния вводятся счетчики.
При переходе из одного состояния в другое увеличивается счетчик полученного и уменьшается для исходного. 
Для того чтобы еще более повысить скорость работы применяется объединение символических состояний.
Оно может произойти, если два состояния отличаются только значением глобальных переменных или локальным состоянием в одном из потоков. 
Такая оптимизация эффективно себя показывает при анализе программ, состоящих из большого количества одинаковых потоков.
В случае, если функции, которые выполняются в отдельных потоках, являются различными, такой подход оказывается бесполезным.

% -- Partial Order Reduction

В статье~\cite{Kahlon:2009:SRTI} рассматриваются идеи уменьшения пространства состояний на основе редукции частичных порядков и применении слайсинга.
Основной идеей редукции является определение независимых блоков с целью исключения их детального анализа с учетом всех возможных чередований потоков.
Зависимость операций определяется по работе с разделяемыми данными, при этом разработан специальный анализ алиасов с использованием обновляющихся последовательностей.
Слайсинг применяется для уменьшения количества рассматриваемых операторов. Некоторые операцторы программы могут быть опущенны из-за ограничений на примитивы синхронизации или из-за недостижимости соответствующих частей кода.

Оценка инструмента проводилась на 9 драйверах Linux с известными гонками. Ожидаемо оказалось, что время работы инструмента является приемлемым только для примеров с небольшим количеством (порядка десятка) разделяемых переменных.
Трассы, построенные на основе полученных предупреждений, подавались на вход BMC, который пытался их доказать. В отдельных случаях, время доказательства занимало 10 часов. 

В статье ~\cite{Kahlon:2009} представлен новый подход к редукции частичных порядков, называемый монотонной редукцией.
Он основан на новой характеристике частичного порядка, которая определяется через вычисления данной программы в терминах квазимонотонных последовательностей.
Этот подход может быть использован и точными, и символическими методами проверки моделей.
%В статье показано, что ограничения на взаимодействие потоков, построенные на основе квазимонотонных последовательностей гарантируют и корректность, и полноту. 
%Отношение независимости определяется, как возможность переставлять операции в двух потоках. Представляеются две стратегии: оптимальная частичная редукция частичных порядков и частичная редукция “дверного глазка” (peephole).
% Для оценки результатов использовался модифицированный тест, известный как “обедающие философы”.
%Сравнение предлагаемого алгоритма производилось со стандартной стратегией BMC.

Некоторые развития подхода к редукции частичных порядков представлены в статье~\cite{Abdulla:2014}.
Экспериментальные данные показывают большое ускорение по сравнению с оригинальным методом, однако, как и в статье~\cite{Basler:2009}, такие результаты возможны только на таких программах, потоки в которых выполняют однотипные действия. 

В работе~\cite{KroeningLMST15} авторы предлагают расширение для редукции частичных порядков для анализа низкоуровневых программ, содержащих вложенные прерывания. 
Как и все оптимизации при попытке рассмотреть чередования, этот подход также страдает недостаточной масштабируемостью. 
Даже на небольших примерах, он не может доказать корректность программы, уходя в таймаут.

Как мы видим, очень много исследователей развивают методы статической верификации, основанные на переборе возможных чередований операций нескольких потоков. 
Несмотря на обилие различных техник и оптимизаций, характерное время работы инструмента анализа составляет порядка 1с на 1 строку кода. 
Поэтому такие методы не могут быть применены на практике.

%--- Translation

Уже упоминались подходы, которые применяют трансляцию параллельную программу в последовательную для последующей верификации.
Следует отметить статьи, посвященные отдельно этой проблеме трансляции (англ. sequentilization) с последующей ее верификацией существующими инструментами анализа последовательных программ.
Все существующие трансляторы используют следующие ограничения: 
\begin{enumerate}
\item число активных потоков ограничено;
\item взаимодействие между потоками возможно только с помощью глобальных переменных;
\item в каждый момент времени только один поток может быть активен;
\end{enumerate}
Известны несколько методов трансляции ~\cite{Torre:2009, Ghafari:2010,Inverso:2014, Tomasco:2015}: от простого дублирования исполняемого кода до использования сложных и оптимизированных карт памяти, переключение между которыми происходит в случайный момент.
Для верификации новой последовательной программы применяются две основные парагдимы. Одна из них - это логическая проверка моделей, при которой формулы строятся для конечного пути, а проверяется их выполнимость.
Второй вариант - это верификация условий (verification-condition, VC), при которой для построения формул требуется пред- и постусловия и формальные правила преобразования. Эксперименты показали, что эти две парагдимы сильно отличаются, и для них нужны различные способы трансляции. 
Все попытки применения подхода трансяции к последовательной программе в общем случае показывают, что он плохо масштабируется и на реальных программах пока не может быть использован. 

%Однако, этот подход может показывать хорошие результаты, если выбрать специальный класс 
Нужно заметить, что трансляции параллельной программы может производиться не в последовательную, а в некоторую промежуточную модель.
Эта модель может быть использована, например, для генерации тестов как это сделано в~\cite{KIM200921}.
В ней представлен фраймворк который автоматически транслирует программу на языке C СИ в модель на языке Promela~\cite{SPIN}.
Полученная модель верифицируется с помощью инструмента SPIN~\cite{SPIN}.
При наличие ошибки полученный контрпример может быть специальным образом преобразован к исполняемому тесту.

В статье~\cite{Atig:2009} авторы рассматривают проблему трансляции программ с динамическим созданием потоков, т.н. асинхроннными вызовами.
Число создаваемых потоков может быть потенциально бесконечным, хотя число переключений каждого потока является ограниченным.
Эта задача сводится к вопросу о покрытии сетей Петри. Ее решение основано на том, что число потоков, создаваемых из конкретного состояния, включающего локальные и глобальные переменные, конечно.
Авторы доказывают несколько теорем из которых следует алгоритмическая разрешимость задачи за конечное время, однако идеи не получили экспериментального подтверждения.

В статье~\cite{Liang:2017} авторы рассматривают проблему проверки низкоуровневого системного кода, содержащего обработчики прерывания.
Основная проблемы заключается в том, что обработчики прерываний в реальной системе выполняются с высоким приоритетом, и их выполнение не может быть прервано переключением на другой поток.
То есть, прерывания выполняются атомарно, если не приходит другое прерывание с более высоким приоритетом.
В статье предложено два подхода к верификации таких программ: на основе трансляции в последовательную и на основе моделирования прерываний, как обычных потоков.
В качестве основного инструмента верификации использовался CBMC.
Было проведено достаточно серьезное сравнение с другими инструментами.

Одним из успешных инструментов является WHOOP~\cite{WHOOP}, который использует технику трансляции и фактически не учитывает взаимодействие потоков.
Он использует только алгоритм Lockset и не имеет возможности расширить подход другими видами анализа.
Авторы предлагают применять этот инструмент в связке с более точным инструментом верификации CORALL. 

%----

В статье ~\cite{Cohen:2009} авторы подходят к проблеме поиска доказательства для многопоточной программы с другой стороны. 
%Для доказательства выполнения некоторого свойства многие инструменты проверки моделей вычисляют достижимые состояния и в каждом из них проверяют выполнение требуемого свойства.
%Другой подход заключается в локальном доказательстве.
Для каждого из потоков записывается свой инвариант в терминах глобальных переменных и доказывается его корректность, а из конъюнкции всех инвариантов следует выполнимость необходимого свойства для целой программы. 
Главная проблема заключается в том, что не всякое доказательство может быть выражено через локальное. И в этом случае поиск локального доказательства будет бесконечным.
Основное достижение данной статьи в том, что был предложен конечный метод для поиска локального доказательства. 
Во многих тестах (со слов авторов) их подход показал хорошие результаты. 

Для помощи инструменту верификации можно предоставлять некоторые подсказки - аннотации. Вовлечение человека в процесс верификации несомненно повышает качество и скорость, однако требует определенных затрат времени на написание таких аннотаций. 
В статье ~\cite{VCC:2009} представлен верифицирующий Си компилятор (VCC), который интегрирован в Microsoft Visual Studio. Это полностью автоматическая система, которая может верифицировать аннотированные программы. Аннотации представляют собой инварианты, пред- и постусловия. Из аннотаций генерируются формулы логики первого порядка, которые разрешаются с помощью решателя.

Похожая идея демонстрируется в статье ~\cite{Burnim:2009}, в которой представлен фреймворк для аннотации Java программ. Аннотации представляют пред- и постусловия для некоторых блоков кода, которые проверяются по ходу выполнения программы. 
Для оценки работы инструмента использовалось два набора тестов: Java Grande Forum (JGF) и Parallel Java (PJ) Library, в сумме 13 тестов 1000-4000 строк кода. В среднем потребовалось около 10 строк аннотаций, чтобы найти те же гонки, что и CalFuzzer. 

%В статье ~\cite{Yahav:2008} описывается фреймворк для доказательства корректности параллельных программ, которые динамически выделяют память.
%Он позволяет встраивать в себя различные алгоритмы доказательства для различных свойств безопасности.
%Семантика Java-программы описывается с помощью мета-языка, основанного на логике первого порядка.
%Далее, вычисляется аппроксимация множества достижимых состояний (обычно бесконечного).
%С помощью теории абстрактной интерпретации формулируются абстрактные состояния, которые представляют некоторое множество конкретных достижимых состояний.
%
%Для каждого оператора программы вычисляется эффект, или действие, которое представляет собой формулу логики первого порядка.
%Это является важным отличием от других инструментов проверки моделей, в которых используется логика высказываний.
%Действие может изменить абстрактное состояние. При получении нового абстрактного состояния фреймворк проверяет, что оно удовлетворяет сформулированным свойствам безопасности. 
%Таким образом, может быть получено ложное предупреждение о нарушении свойства, но оно никогда не будет пропущено.
%
%Описываемый фреймворк производит верификацию и анализ указателей одновременно, что позволяет повысить точность.
%Фреймворк оценивался на восьми тестах, представляющие собой различные реализации очереди и способов работы с ней.
%Самый большой тест занял около двух часов.

%Статья~\cite{Ganty:2009:POPL} посвящена проблеме проверки живучести асинхронных программ.
%Задача ставится: проверить свойства завершаемости и неголодания. Завершаемость означает, что из каждой процедуры есть возврат и нет бесконечного запуска процедур.
%Второе свойство - неголодания (non-starvation) означает, что из каждой процедуры есть возврат, а при бесконечном выполнении все процедуры обрабатываются, то есть нет такой, выполнение которой постоянно откладывается. 
%Доказательство этих двух свойств осложняется тем, что программа потенциально может содержать неограниченное количество вызовов функций, например, из-за рекурсии.
%Статья крайне теоретизирована, и нет никаких экспериментов.

Очень интересная идея была описана в статье ~\cite{Leino:2009}. В ней представлен подход к верификации многопоточных программ, основанный на понятии разрешения.
Так, поток имеет право на доступ к некоторой ячейке памяти, если у него есть на это разрешение, которое представляет вероятность от 0 до 100\% включительно.
Значение 100\% означает эксклюзивный доступ на запись, любое другое число от 0 до 100 - доступ на чтение.
Для каждой функции записывается предусловие, в котором указывается, какое значение для разрешения требуется для ее выполнения.
Отдельно нужно заметить, что рассматриваются объектно-ориентированные программы, в которых синхронизация между потоков осуществляется с помощью мониторов.
Мониторы представляют собой блокировки, которые используются для защиты от одновременного доступа некоторые области памяти.
Во время создания нового объекта или захвата монитора для него разрешение устанавливается на 100\%.
При доступе к объекту строится формула из ограничений и подается на вход решателю.
Никаких экспериментов не было проведено.

Все рассмотренные выше подходы так или иначе учитывают взаимодействие потоков друг с другом. 
На реальных программных системах это приводит к комбинаторному взрыву числа возможных вариантов выполнения нескольких потоков.
Для решения этой проблемы был предложен подход с абстракцией от окружения потока, т.н. подход с раздельным рассмотрением потоков (англ. thread-modular approach). 
В самом простом варианте этот подход был описан еще в~\cite{ThreadModular03}.
%Our approach is based on similar ideas, but also use an abstraction.
Затем этот подход был дополнен предикатной абстракцией в~\cite{Henzinger:2004}.
В этой статье пока рассматривался только один поток в нескольких копиях, то есть окружение формировалось самим же потоком, а примитивы синхронизации вообще не использовались.

Расширение подхода с раздельным рассмотрением потоков и абстракцией было представлено в~\cite{Malkis:2006}, а затем реализовано в инструменте TAR~\cite{TAR}.
В этом подходе была предложена идея эффектов от потока, которые вычислялись на основе действий потока.
Эти эффекты затем применялись к другим потокам.
Примитивы синхронизации были реализованы, как обыкновенные переменные.

В статье\cite{ShapeTM} представлено применение подхода с раздельным рассмотрением потоков для анализа динамически выделяемой памяти (англ. Shape analysis). 
В подходе предполагалось итеративное построение инвариантов памяти для доказательства корректной работы с памятью в многопоточной программе.
Несмотря на интересную идею, применение данного инструмента было возможно на небольших тестовых программах, подготовленных на основе драйверов ОС Windows.

Похожие идеи были представлены в статьях~\cite{Threader:2011,Gupta:2011:POPL,Gupta:2011}, которые представляют инструмент Threader.
Основная идея метода заключается в поиске некоторого инварианта для программы, из которого следует доказываемое свойство.
В процессе анализа строится абстракция, при этом для окружения используется аппроксимация сверху, основанная на Хорновских дизъюнктах.
Если в какой-то момент возникнет состояние, которое не противоречит проверяемому свойству, абстракция уточняется.
При этом уточняются как состояния этой абстракции, так и эффекты, то есть, взаимодействие потоков.
Threader не ограничивает число возможных переключений контекста.

Для оценки результатов использовались примеры, являющиеся упрощенными моделями некоторых реальных программ, таких, как драйвера ОС Windows и Linux.
В основном, размер тестов варьировался в районе 100 строк, при этом время работы инструмента на некоторых примерах составляло несколько минут, а на некоторых превышало ограничение в 15 минут. 
В статье~\cite{Threader:svcomp} авторы предоставляют результаты запуска инструмента на некотором общедоступном наборе тестов, который используется для ежегодного соревнования инструментов статической верификации. 
В качестве тестовых примеров там используются, в основном, небольшие рукописные программы.
Большинство инструментов, принимающих там участие, не способны справится с более-менее реальным кодом.
Threader запускался на 32 тестах из категории «Параллельность» и набрал 43 балла из 49 возможных. Правильный вердикт был выдан на 28 тестах.

Рассмотренные подходы проверки моделей позволяют обеспечить корректность анализа в определенных ограничениях, однако все они испытывают определенные проблемы при применении к реальному программному обеспечению.
Подход с раздельным рассмотрением потоков является перспективным решением проблемы комбинаторного взрыва числа состояний программы.
При этом существующие подходы все еще не способны применяться к большим программным системам.
Кроме того, все подходы с раздельным рассмотрением потоков концентрировались только на описании непосредственно на формировании окружения, в то время как базовые варианты анализа оставались неэффективными.
Например, во всех реализациях все примитивы синхронизации были записаны, как обычные переменные, и для отслеживания их значений использовался тот же анализ, что и для отслеживания значений переменных.

%\newpage
%============================================================================================================================

\section{Основные выводы}
\label{rw:conclusion}
Проведенный обзор современных методов анализа многопоточных программ позволяет сделать следующие выводы.

Основные усилия сейчас сосредаточены на анализе пользовательских приложений.
Системное программное обеспечение является слишком объемным и слишком сложным для применения общецелевых методов.
Для решения практических задач разрабатываются инструменты специально нацеленные на конкретные классы ошибок или на определенный программный код.
Это является верным для всех типов подходов: как статических, так и динамических.

Методы динамического анализа нацелены, в первую очередь, на повышение процента истинных срабатываний, возможно, жертвуя при этом некоторыми реальными ошибками.
Основными проблемами инструментов динамического анализа является увеличение ресурсов, необходимых для работы программы, в том числе, замедление ее.
И на решение этих проблем направлены основные усилия.
Таким образом, основными направленими развития инструментов динамического анализа сейчас являются разработка различных оптимизаций, позволяющих более эффективно использовать предоставленные ресурсы и повышающих вероятность обнаружить реальную ошибку.
Такие проблемы не соотносятся с задачей поиска состояний гонки в ядре операционной системы.

Общецелевые методы статического анализа нацелены на высокую скорость анализа.
В случае применения таких методов к большому объему сложного кода будет получен огромное количество предупреждений.
Анализ этих предупреждений вручную может затянуться на неопределенное время.
Непрактичность таких методов подтверждается тем, что почти все инструменты данного класса не используются для решения прикладных задач, а являются чисто академическими реализациями. 
Исключениями становятся инструменты созданные для решения очень узкого класса задач, например, поиска специфичных ошибок в отдельном программном продукте.

В результате обзора различных техник статического анализа можно сделать вывод, что почти все инструменты так или иначе используют неточные фильтры и эвристики, в качестве основы своего метода.
Таким образом, они принципиально не позволяют гарантировать отсутствие ошибки.
Такие инструменты, как Relay~\cite{Relay}, которые позволяют отключать свои фильтры, выдают огромное количество ложных предупреждений, так как не учитывают специфику системного кода, взаимодействия потоков и условия, встречающиеся на пути.

Таким образом, и методы динамического анализа, и общецелевые методы статического анализа используются для решения других задач и не подходят для качественной верификации системного программного обеспечения, так как они не могут дать гарантию того, что программа корректна.
%Для прикладных пользовательских программ такой недостаток имеет небольшое значение, так как цена пропущенной ошибки является невысокой.

Методы статической верификации позволяют провести верификацию с высоким уровнем надежности, однако требуют значительного объема ресурсов. 
В настоящее время существует большое число инструментов, реализующих методы на основе автоматической проверки моделей, однако все они являются академическими инструментами, а их применение ограничивается небольшим искусственным набором тестовых программ.

Методы статической верификации, основанные на переборе различных чередований (англ. interleavings), не способны обеспечить достаточной скорости анализа. 
Наиболее подходящим подходом является подход с раздельным рассмотрением потоков, который позволяет анализировать потоки по-отдельности. 

Многие из исследователей, которые пытались применить свои инструменты к системному программному обеспечению, сталкивались с проблемами анализа сложных низкоуровневых конструкций, например, адресной арифметики.
Другой важной особенностью анализа реального программного обеспечения является его принципиальная недоопределенность.
В системном программном обеспечении используются различные источники входных данных, которые не доступны на этапе анализа, например, внешние устройства, действия пользователя или прикладные программы. 
Многие из академических инструментов работают в предположении, что анализируемая программа замкнута, то есть весь используемый код доступен, вся используемая память явно инициализирована.
На практике часто оказывается, что тела некоторых функций находятся в библиотеках и код их не доступен, эти же функции могут возвращать некоторую память, которая неизвестно как инициализирована.
Эту неопределенность необходимо уметь гибко настраивать. 

Многие из инструментов стараются предположить как можно худшее, стараясь не пропустить реальные ошибки.
Но обычно это приводит лишь к огромному множеству ложных срабатываний.
На основе знаний от разработчиков можно выдвинуть некоторые разумные предположения к неопределенным функциям, которые позволят значительно сократить количество найденных ложных предупреждений.
Однако, такие предположения должны быть четко зафиксированы, чтобы полученное доказательство корректности не было ими скомпрометировано.

Еще одним важным различием подходов является определение ошибки. 
Так, методы динамического и статического анализа, по сути, ищут несинхронизированные доступы к памяти.
Методы статической верификации проверяют многопоточную программу на соответствие некоторой спецификации.
Это означает, что пользователь сам должен задать, что является ошибкой.
Примером такой спецификации может быть требование, чтобы значения ни одной разделяемой переменной не могло быть изменено сразу после его чтения или записи.
Это условие является одной из попыток формализовать условия отсутствия состояний гонки.
Однако, выразительности простого языка спецификаций, который обычно реализовывается в инструментах статической верификации, оказывается недостаточно для полного описания тех неформальных требований к программе, которые обычно подразумеваются под словами <<отсутствие состояний гонки>>.
Например, оба этих условия не позволяют формализовать требование к отсутствию таких ошибок, как высокоуровневые гонки.
Также становится невозможным доказывать корректность различных алгоритмах, которые не требуют синхронизации (lock-free).
Таким образом, для проверки сложных требований необходимо иметь возможность написания некоторых пользовательских инвариантов, которые требуется доказать.

Таким образом, можно заключить, что в настоящее время отсутствуют такие методы анализа больших объемов системного кода, в том числе, операционных систем, которые могут обеспечить высокий уровень надежности.
Данная работа посвящена описанию разработанного метода анализа корректности программ, в том числе, поиска состояний гонки, который может применяться к реальным программным системам и позволяет гибко настраивать баланс между точностью и скоростью работы.
